{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "749cb0b7d343d12569698ece840039c7fef54711",
    "colab_type": "text",
    "id": "BUSd8dmWEUf4"
   },
   "source": [
    "# Capstone V6 model\n",
    "\n",
    "Fork from V3.\n",
    "\n",
    "The same model as capstoneV3 but only 2 epochs + trainable embedding + no class weights.\n",
    "\n",
    "The validation F1-score is {} at a threshold of {}."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "85c12f788178232533cbf7f141e217c32b882cda",
    "colab_type": "text",
    "id": "w7oagxHHofxb"
   },
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "f0421d98769ce1b3bcc0b65f729851be0d275cb5"
   },
   "outputs": [],
   "source": [
    "MODEL_VERSION = 'capstoneV6'\n",
    "MAX_SEQUENCE_LENGTH = 100\n",
    "EMBEDDING_DIM = 300\n",
    "MAX_WORDS = 50000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "749cb0b7d343d12569698ece840039c7fef54711",
    "colab_type": "text",
    "id": "BUSd8dmWEUf4"
   },
   "source": [
    "## Common english contraction mappings (wikipedia):\n",
    "https://en.wikipedia.org/wiki/Wikipedia:List_of_English_contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "d5a645a8f6a9f70d9db108cebbc683089e548260"
   },
   "outputs": [],
   "source": [
    "CONTRACTION_MAPPING = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\", \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\", \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",  \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\", \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\", \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\", \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\", \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\", \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\", \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\", \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\", \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\", \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\", \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\", \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\", \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",  \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\", \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\", \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\", \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\", \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\", \"you're\": \"you are\", \"you've\": \"you have\" }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "56282f6e5433223f3823e24e95fe170534e8dcae"
   },
   "outputs": [],
   "source": [
    "PUNCT = \"/-'?!.,#$%\\'()*+-/:;<=>@[\\\\]^_`{|}~\" + '\"\"“”’' + '∞θ÷α•à−β∅³π‘₹´°£€\\×™√²—–&'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "a2a79c0d80f797d3868fac83217b1e2479bee8dc"
   },
   "outputs": [],
   "source": [
    "SPECIAL_PUNCT = {'\\u200b': ' ', '…': ' ... ', '\\ufeff': '', 'करना': '', 'है': ''}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "451df1dd80192c375340a023e852cab39698d434"
   },
   "outputs": [],
   "source": [
    "PUNCT_MAPPING = {\"‘\": \"'\", \"₹\": \"e\", \"´\": \"'\", \"°\": \"\", \"€\": \"e\", \"™\": \"tm\", \"√\": \" sqrt \", \"×\": \"x\", \"²\": \"2\", \"—\": \"-\", \"–\": \"-\", \"’\": \"'\", \"_\": \"-\", \"`\": \"'\", '“': '\"', '”': '\"', '“': '\"', \"£\": \"e\", '∞': 'infinity', 'θ': 'theta', '÷': '/', 'α': 'alpha', '•': '.', 'à': 'a', '−': '-', 'β': 'beta', '∅': '', '³': '3', 'π': 'pi', }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "228dc3ca14b0b0af33d6c874400d8f01ef96a874"
   },
   "outputs": [],
   "source": [
    "MISPELL_MAPPING = {'colour': 'color', 'centre': 'center', 'favourite': 'favorite', 'travelling': 'traveling', 'counselling': 'counseling', 'theatre': 'theater', 'cancelled': 'canceled', 'labour': 'labor', 'organisation': 'organization', 'wwii': 'world war 2', 'citicise': 'criticize', 'youtu ': 'youtube ', 'Qoura': 'Quora', 'sallary': 'salary', 'Whta': 'What', 'narcisist': 'narcissist', 'howdo': 'how do', 'whatare': 'what are', 'howcan': 'how can', 'howmuch': 'how much', 'howmany': 'how many', 'whydo': 'why do', 'doI': 'do I', 'theBest': 'the best', 'howdoes': 'how does', 'mastrubation': 'masturbation', 'mastrubate': 'masturbate', \"mastrubating\": 'masturbating', 'pennis': 'penis', 'Etherium': 'Ethereum', 'narcissit': 'narcissist', 'bigdata': 'big data', '2k17': '2017', '2k18': '2018', 'qouta': 'quota', 'exboyfriend': 'ex boyfriend', 'airhostess': 'air hostess', \"whst\": 'what', 'watsapp': 'whatsapp', 'demonitisation': 'demonetization', 'demonitization': 'demonetization', 'demonetisation': 'demonetization', 'pokémon': 'pokemon'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "974ca8fb2157648f2ace9c41bf37e0d87dd2eb20",
    "colab_type": "text",
    "id": "w7oagxHHofxb"
   },
   "source": [
    "# Helpers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "408f2ecb4a7380c2a57635996ca248020e4aaa94",
    "colab_type": "text",
    "id": "BUSd8dmWEUf4"
   },
   "source": [
    "## Embedding helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "88880adc1b1e2ca67e77db81d36165fad52d9e1c"
   },
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def loadEmbeddings(path, dimensions, mode='r', encoding=None, errors=None):\n",
    "    print('Loading embeddings from: %s' %path)\n",
    "    embeddings = {}\n",
    "    f = open(path, buffering=((2<<16) + 8), mode=mode, encoding=encoding, errors=errors)\n",
    "    for line in f:\n",
    "        if len(line) <= 100:\n",
    "            continue\n",
    "        values = line.split()\n",
    "        word = ''.join(values[:-dimensions])\n",
    "        coefs = np.asarray(values[-dimensions:], dtype='float32')\n",
    "        embeddings[word] = coefs\n",
    "    f.close()\n",
    "    print('Found %s word vectors.' % len(embeddings))\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "1f202cf2766c8d2a73834f057bd195928136ce1b"
   },
   "outputs": [],
   "source": [
    "def loadEmbeddingsGensim(path, dimensions, binary=True):\n",
    "    print('Loading embeddings from: %s' %path)\n",
    "    embeddings = {}\n",
    "    gensim_vecs = KeyedVectors.load_word2vec_format(path, binary=binary)\n",
    "    for word, vector in zip(gensim_vecs.vocab, gensim_vecs.vectors):\n",
    "        coefs = np.asarray(vector[-dimensions:], dtype='float32')\n",
    "        embeddings[word] = coefs\n",
    "    print('Found %s word vectors.' % len(embeddings))\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "344bdbebf5757946836407ee4a0a8ace39b65228",
    "colab": {},
    "colab_type": "code",
    "id": "0KeJJofUpQm9"
   },
   "outputs": [],
   "source": [
    "def getEmbeddingMatrix(embedding, word_index):\n",
    "    all_embs = np.stack(embedding.values())\n",
    "    emb_mean,emb_std = all_embs.mean(), all_embs.std()\n",
    "    embed_size = all_embs.shape[1]\n",
    "    \n",
    "    nb_words = min(MAX_WORDS, len(word_index))\n",
    "    embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embed_size))\n",
    "    for word, i in word_index.items():\n",
    "        if i >= MAX_WORDS:\n",
    "            continue\n",
    "        embedding_vector = embedding.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "    \n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e462ed6a5cd6b481db42664c68c3451b61026d76",
    "colab_type": "text",
    "id": "BUSd8dmWEUf4"
   },
   "source": [
    "### Helper to replace contractions in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "e9cd4f331303cea868030ed771c30c01a65f74a7"
   },
   "outputs": [],
   "source": [
    "def clean_contractions(text):\n",
    "    specials = [\"’\", \"‘\", \"´\", \"`\"]\n",
    "    for s in specials:\n",
    "        text = text.replace(s, \"'\")\n",
    "    text = ' '.join([CONTRACTION_MAPPING[t] if t in CONTRACTION_MAPPING else t for t in text.split(\" \")])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4d9fd63b54dda11ec562c8e2c85fa386e9910958",
    "colab_type": "text",
    "id": "BUSd8dmWEUf4"
   },
   "source": [
    "### Helper to remap punctuations in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "c1b038b3cadf6c09fcb2523a1171ad8e95a1700d"
   },
   "outputs": [],
   "source": [
    "def clean_special_chars(text):\n",
    "    for p in PUNCT_MAPPING:\n",
    "        text = text.replace(p, PUNCT_MAPPING[p])\n",
    "    \n",
    "    for p in PUNCT:\n",
    "        text = text.replace(p, ' ' + p + ' ')\n",
    "    \n",
    "    for s in SPECIAL_PUNCT:\n",
    "        text = text.replace(s, SPECIAL_PUNCT[s])\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "dbcf585e91cd7faad3c230d6eb191dc39695db17",
    "colab_type": "text",
    "id": "BUSd8dmWEUf4"
   },
   "source": [
    "### Helper to correct common mispellings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "186bf0c75630a56d02120c197712e4fb5681ad8d"
   },
   "outputs": [],
   "source": [
    "def correct_spelling(x):\n",
    "    for word in MISPELL_MAPPING.keys():\n",
    "        x = x.replace(word, MISPELL_MAPPING[word])\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "92cc1a4a5777c338f819adde4ec455d9856013dc",
    "colab_type": "text",
    "id": "BUSd8dmWEUf4"
   },
   "source": [
    "## Coverage helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "20732a275083041d5a06ad4bd6a7938f7333afda"
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def build_vocab(texts):\n",
    "    sentences = texts.apply(lambda x: x.split()).values\n",
    "    vocab = Counter()\n",
    "    for sentence in sentences:\n",
    "        for word in sentence:\n",
    "            vocab[word] += 1\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "b83aab607f791f5824b3eca4277741950cd36d92"
   },
   "outputs": [],
   "source": [
    "import operator\n",
    "\n",
    "def check_coverage(vocab, embeddings_index):\n",
    "    known_words = {}\n",
    "    unknown_words = {}\n",
    "    nb_known_words = 0\n",
    "    nb_unknown_words = 0\n",
    "    for word in vocab.keys():\n",
    "        try:\n",
    "            known_words[word] = embeddings_index[word]\n",
    "            nb_known_words += vocab[word]\n",
    "        except:\n",
    "            unknown_words[word] = vocab[word]\n",
    "            nb_unknown_words += vocab[word]\n",
    "            pass\n",
    "\n",
    "    print('Found embeddings for {:.2%} of vocab'.format(len(known_words) / len(vocab)))\n",
    "    print('Found embeddings for  {:.2%} of all text'.format(nb_known_words / (nb_known_words + nb_unknown_words)))\n",
    "    unknown_words = sorted(unknown_words.items(), key=operator.itemgetter(1))[::-1]\n",
    "\n",
    "    return unknown_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "70e187637082e5f448863c5f965fff8ab80ed065",
    "colab_type": "text",
    "id": "w7oagxHHofxb"
   },
   "source": [
    "# Import test/train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_uuid": "e20e43f9ea433ee2eee88003355ef86f724fa01c",
    "colab": {},
    "colab_type": "code",
    "id": "X3n8bRW6WcKo"
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"../input/train.csv\")\n",
    "test_df = pd.read_csv(\"../input/test.csv\")\n",
    "\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.max_rows = None\n",
    "pd.options.display.max_colwidth = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2052ad18f26ea6c28d4feeaac402d61438a6f1cf",
    "colab_type": "text",
    "id": "w7oagxHHofxb"
   },
   "source": [
    "# Analyze train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_uuid": "8f55a111d1222a541a6cc5938de12577b3b12215",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 393
    },
    "colab_type": "code",
    "id": "h0aRi6Toaq8j",
    "outputId": "5d5c6246-c8c3-49e0-e8b7-58850a83f62f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample insincere questions\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>question_text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>641655</th>\n",
       "      <td>7dad3cbff77b5055fb80</td>\n",
       "      <td>When will those idiots learn not to blame the paper or organiser for their results in the JEE?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1012493</th>\n",
       "      <td>c668d229641d080c1199</td>\n",
       "      <td>Why did the Whig Party die out, and why won't Republicans and Democrats do the same?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>630149</th>\n",
       "      <td>7b65c91f70a9ee230805</td>\n",
       "      <td>Did Jesus kill anyone for fun?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>622909</th>\n",
       "      <td>79faaff0e6ce56d68364</td>\n",
       "      <td>Hydraulic is spelled like this you ninnies.Since you cant spell do you like this.?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203511</th>\n",
       "      <td>27c71463755e96d15bbb</td>\n",
       "      <td>Am I the only one who hates Indians? What is your experience?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117459</th>\n",
       "      <td>16fd113c2467bf3afbe8</td>\n",
       "      <td>Is it fair to displace millions of Palestinians and establish apartheid? Why aren't people stopping this?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>616556</th>\n",
       "      <td>78bd334b3682ea3a4515</td>\n",
       "      <td>Why don’t the Hindu extremists want India to be a liberal country?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610984</th>\n",
       "      <td>77a6284c0c19d255e50a</td>\n",
       "      <td>Are north Indians stupid compared to south Indians?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503146</th>\n",
       "      <td>628484a150d663594234</td>\n",
       "      <td>Why isn't there a decent leader amongst the Muslims? The current prominent ones appear to be bigots, or despots or extremists.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>922256</th>\n",
       "      <td>b4b92a705c56690246be</td>\n",
       "      <td>Do women understand they're hypocrites when they claim to want nice/friendly men but chase after men who treat them terribly?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          qid  \\\n",
       "641655   7dad3cbff77b5055fb80   \n",
       "1012493  c668d229641d080c1199   \n",
       "630149   7b65c91f70a9ee230805   \n",
       "622909   79faaff0e6ce56d68364   \n",
       "203511   27c71463755e96d15bbb   \n",
       "117459   16fd113c2467bf3afbe8   \n",
       "616556   78bd334b3682ea3a4515   \n",
       "610984   77a6284c0c19d255e50a   \n",
       "503146   628484a150d663594234   \n",
       "922256   b4b92a705c56690246be   \n",
       "\n",
       "                                                                                                                          question_text  \\\n",
       "641655   When will those idiots learn not to blame the paper or organiser for their results in the JEE?                                   \n",
       "1012493  Why did the Whig Party die out, and why won't Republicans and Democrats do the same?                                             \n",
       "630149   Did Jesus kill anyone for fun?                                                                                                   \n",
       "622909   Hydraulic is spelled like this you ninnies.Since you cant spell do you like this.?                                               \n",
       "203511   Am I the only one who hates Indians? What is your experience?                                                                    \n",
       "117459   Is it fair to displace millions of Palestinians and establish apartheid? Why aren't people stopping this?                        \n",
       "616556   Why don’t the Hindu extremists want India to be a liberal country?                                                               \n",
       "610984   Are north Indians stupid compared to south Indians?                                                                              \n",
       "503146   Why isn't there a decent leader amongst the Muslims? The current prominent ones appear to be bigots, or despots or extremists.   \n",
       "922256   Do women understand they're hypocrites when they claim to want nice/friendly men but chase after men who treat them terribly?    \n",
       "\n",
       "         target  \n",
       "641655   1       \n",
       "1012493  1       \n",
       "630149   1       \n",
       "622909   1       \n",
       "203511   1       \n",
       "117459   1       \n",
       "616556   1       \n",
       "610984   1       \n",
       "503146   1       \n",
       "922256   1       "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Sample insincere questions\")\n",
    "train_df.loc[train_df['target'] == 1].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_uuid": "73bd9f42266c6c2184ff65017ccb5f62e38314f5",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 376
    },
    "colab_type": "code",
    "id": "n_mslOIdaj8G",
    "outputId": "c0c9da0b-96d8-436f-fe37-28a2da1d6b69"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample sincere questions\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>question_text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1034713</th>\n",
       "      <td>cac22f0f7e6806be4053</td>\n",
       "      <td>How can I remove my mind from thinking about some personal problems and focus on my studies?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>827435</th>\n",
       "      <td>a228aba25900300abc47</td>\n",
       "      <td>What is the confidence cycle?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1023774</th>\n",
       "      <td>c89e03dfba1ab50b6fec</td>\n",
       "      <td>Wher Al Capone born?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456283</th>\n",
       "      <td>596115bfe9b2232bc3f5</td>\n",
       "      <td>Do you think the obsession of money is creating financial disparities in the workplace, in health care and several other parameters, if so what can be done to reduce financial disparities even to the vulnerable populations?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165295</th>\n",
       "      <td>204e141de21df52aa6ab</td>\n",
       "      <td>Who all are some good local tour operators in Macau?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>722708</th>\n",
       "      <td>8d7bf918f6a78176ae63</td>\n",
       "      <td>What does debt funding instead of VC round say about a startup?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1131409</th>\n",
       "      <td>ddbd159c3064d52b9662</td>\n",
       "      <td>How can I launch my own token for crypto currency in India? How much capital will I need to invest?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>868608</th>\n",
       "      <td>aa3068d4a7f027682963</td>\n",
       "      <td>As a former data scientist who wants a career change, how should I figure out what to do next? After 5+ years, I feel extremely tired of sitting in front of the screen and writing code all the time. Where should I start?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118043</th>\n",
       "      <td>171c603ffa28004556a2</td>\n",
       "      <td>Have you switched from Canon DSLRs to Sony? Do you love or hate the switch, and why?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>948973</th>\n",
       "      <td>b9f29d48227fa636a690</td>\n",
       "      <td>Punjabi's be like if you failed to go abroad then you are unsuccessful is that true?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          qid  \\\n",
       "1034713  cac22f0f7e6806be4053   \n",
       "827435   a228aba25900300abc47   \n",
       "1023774  c89e03dfba1ab50b6fec   \n",
       "456283   596115bfe9b2232bc3f5   \n",
       "165295   204e141de21df52aa6ab   \n",
       "722708   8d7bf918f6a78176ae63   \n",
       "1131409  ddbd159c3064d52b9662   \n",
       "868608   aa3068d4a7f027682963   \n",
       "118043   171c603ffa28004556a2   \n",
       "948973   b9f29d48227fa636a690   \n",
       "\n",
       "                                                                                                                                                                                                                           question_text  \\\n",
       "1034713  How can I remove my mind from thinking about some personal problems and focus on my studies?                                                                                                                                      \n",
       "827435   What is the confidence cycle?                                                                                                                                                                                                     \n",
       "1023774  Wher Al Capone born?                                                                                                                                                                                                              \n",
       "456283   Do you think the obsession of money is creating financial disparities in the workplace, in health care and several other parameters, if so what can be done to reduce financial disparities even to the vulnerable populations?   \n",
       "165295   Who all are some good local tour operators in Macau?                                                                                                                                                                              \n",
       "722708   What does debt funding instead of VC round say about a startup?                                                                                                                                                                   \n",
       "1131409  How can I launch my own token for crypto currency in India? How much capital will I need to invest?                                                                                                                               \n",
       "868608   As a former data scientist who wants a career change, how should I figure out what to do next? After 5+ years, I feel extremely tired of sitting in front of the screen and writing code all the time. Where should I start?      \n",
       "118043   Have you switched from Canon DSLRs to Sony? Do you love or hate the switch, and why?                                                                                                                                              \n",
       "948973   Punjabi's be like if you failed to go abroad then you are unsuccessful is that true?                                                                                                                                              \n",
       "\n",
       "         target  \n",
       "1034713  0       \n",
       "827435   0       \n",
       "1023774  0       \n",
       "456283   0       \n",
       "165295   0       \n",
       "722708   0       \n",
       "1131409  0       \n",
       "868608   0       \n",
       "118043   0       \n",
       "948973   0       "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Sample sincere questions\")\n",
    "train_df.loc[train_df['target'] == 0].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_uuid": "7b8a948c3ae97a09decf8f0a6fadff9eed5f83b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.93813\n",
      "1    0.06187\n",
      "Name: target, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "target_ratios = train_df.target.value_counts(normalize=True)\n",
    "\n",
    "print(target_ratios)\n",
    "\n",
    "target_ratios.plot(kind='bar', title='Ratios (target)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_uuid": "323d3c4ed532d94120a8681d822c5ad60fc6abae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average word length of questions in train is 13.\n",
      "Average word length of questions in test is 13.\n"
     ]
    }
   ],
   "source": [
    "print('Average word length of questions in train is {0:.0f}.'.format(np.mean(train_df['question_text'].apply(lambda x: len(x.split())))))\n",
    "print('Average word length of questions in test is {0:.0f}.'.format(np.mean(test_df['question_text'].apply(lambda x: len(x.split())))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_uuid": "3b49c4e9bbe8ab8ccddfc8b9c8b24bcafe1bbd3c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max word length of questions in train is 134.\n",
      "Max word length of questions in test is 87.\n"
     ]
    }
   ],
   "source": [
    "print('Max word length of questions in train is {0:.0f}.'.format(np.max(train_df['question_text'].apply(lambda x: len(x.split())))))\n",
    "print('Max word length of questions in test is {0:.0f}.'.format(np.max(test_df['question_text'].apply(lambda x: len(x.split())))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_uuid": "83ede400076de1e67b90de70553ae273d0b16473"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average character length of questions in train is 71.\n",
      "Average character length of questions in test is 70.\n"
     ]
    }
   ],
   "source": [
    "print('Average character length of questions in train is {0:.0f}.'.format(np.mean(train_df['question_text'].apply(lambda x: len(x)))))\n",
    "print('Average character length of questions in test is {0:.0f}.'.format(np.mean(test_df['question_text'].apply(lambda x: len(x)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_uuid": "1b66752d7dfea96b9c5b171edfe6f6d2831956a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max character length of questions in train is 1017.\n",
      "Max character length of questions in test is 588.\n"
     ]
    }
   ],
   "source": [
    "print('Max character length of questions in train is {0:.0f}.'.format(np.max(train_df['question_text'].apply(lambda x: len(x)))))\n",
    "print('Max character length of questions in test is {0:.0f}.'.format(np.max(test_df['question_text'].apply(lambda x: len(x)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "_uuid": "5ff56f79415f02f3a029a2a12c40444410427763"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p999 character length of questions in train is 249.\n",
      "p999 character length of questions in test is 249.\n"
     ]
    }
   ],
   "source": [
    "print('p999 character length of questions in train is {0:.0f}.'.format(np.percentile(train_df['question_text'].apply(lambda x: len(x)), 99.9)))\n",
    "print('p999 character length of questions in test is {0:.0f}.'.format(np.percentile(test_df['question_text'].apply(lambda x: len(x)), 99.9)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "755dc21b8d2ad16d4711e5f3cfc664617fba4a3f",
    "colab_type": "text",
    "id": "QIn-67cmvDFk"
   },
   "source": [
    "# Data processing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e32a7c365a4f71149537c44eca72b762c0cf1a8b",
    "colab_type": "text",
    "id": "QIn-67cmvDFk"
   },
   "source": [
    "## TODO: Feature engineering\n",
    "\n",
    "Add feature engineering here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "_uuid": "a65029f02944902ad1c4a3b988ba4d166ce26910"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 49.3 s, sys: 320 ms, total: 49.6 s\n",
      "Wall time: 49.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "train_df['treated_question'] = train_df['question_text'].apply(lambda x: x.lower())\n",
    "train_df['treated_question'] = train_df['treated_question'].apply(lambda x: clean_contractions(x))\n",
    "train_df['treated_question'] = train_df['treated_question'].apply(lambda x: clean_special_chars(x))\n",
    "train_df['treated_question'] = train_df['treated_question'].apply(lambda x: correct_spelling(x))\n",
    "\n",
    "test_df['treated_question'] = test_df['question_text'].apply(lambda x: x.lower())\n",
    "test_df['treated_question'] = test_df['treated_question'].apply(lambda x: clean_contractions(x))\n",
    "test_df['treated_question'] = test_df['treated_question'].apply(lambda x: clean_special_chars(x))\n",
    "test_df['treated_question'] = test_df['treated_question'].apply(lambda x: correct_spelling(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ab9fc29433d90e5d99d5fe728bb92d3c613a1e9f",
    "colab_type": "text",
    "id": "QIn-67cmvDFk"
   },
   "source": [
    "## Fill data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "_uuid": "c3eff454f10f0f7ca9552205a993b094fa5b5c57",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "bbmOu7FPvNgI",
    "outputId": "653bd496-0185-474a-d557-9d3d2dbacf08"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1306122 training questions.\n",
      "Found 56370 test questions.\n"
     ]
    }
   ],
   "source": [
    "X_train = train_df['treated_question'].fillna('+++').tolist()\n",
    "y_train = train_df['target']\n",
    "X_test = test_df['treated_question'].fillna('+++').tolist()\n",
    "\n",
    "\n",
    "print('Found %s training questions.' % len(X_train))\n",
    "print('Found %s test questions.' % len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "_uuid": "d9bb5e7c69abf941c142775505c87fb8804f6345",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "_kbWqXCezaBA",
    "outputId": "79004f92-5f67-4ceb-caf0-01a78506cb9f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (1306122, 100)\n",
      "Shape of y_train: (1306122,)\n",
      "Found 195975 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "tokenizer = Tokenizer(num_words=MAX_WORDS, lower=True, split=' ', filters='',\n",
    "                       char_level=False, oov_token=None, document_count=0,\n",
    "                      )\n",
    "                                   \n",
    "tokenizer.fit_on_texts(X_train)\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_train = pad_sequences(X_train, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "X_test = tokenizer.texts_to_sequences(X_test)\n",
    "X_test = pad_sequences(X_test, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "print('Shape of X_train:', X_train.shape)\n",
    "print('Shape of y_train:', y_train.shape)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "print('Found %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "aedafbcf978e9c8eb2db0fa3fc650762f02d87a0",
    "colab_type": "text",
    "id": "BUSd8dmWEUf4"
   },
   "source": [
    "## Save tokenized data + word index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 296 ms, sys: 616 ms, total: 912 ms\n",
      "Wall time: 2.84 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import gc\n",
    "import pickle\n",
    "\n",
    "test_df.to_pickle('test_df.pkl')\n",
    "\n",
    "np.save('X_train.npy', X_train)\n",
    "np.save('X_test.npy', X_test)\n",
    "y_train.to_pickle('y_train.pkl')\n",
    "\n",
    "pickle.dump(word_index, open('word_index.pkl', 'wb'))\n",
    "\n",
    "del X_train\n",
    "del X_test\n",
    "del y_train\n",
    "\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "aedafbcf978e9c8eb2db0fa3fc650762f02d87a0",
    "colab_type": "text",
    "id": "BUSd8dmWEUf4"
   },
   "source": [
    "## Build vocabulary with counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "_uuid": "860e94814f74b4282fce01a2c8c42d7c29d1dabf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13.8 s, sys: 548 ms, total: 14.4 s\n",
      "Wall time: 14.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "train_vocab = build_vocab(train_df['treated_question'])\n",
    "del train_df\n",
    "test_vocab = build_vocab(test_df['treated_question'])\n",
    "del test_df\n",
    "\n",
    "vocab = train_vocab + test_vocab\n",
    "del train_vocab\n",
    "del test_vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e1d40498bd469f8c5784570ddb88bb65a6367064",
    "colab_type": "text",
    "id": "BUSd8dmWEUf4"
   },
   "source": [
    "## Load embeddings, measure coverage and save embedding matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aNd1KcNjsvxj"
   },
   "source": [
    "# Restore point (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n%%time\\n\\nimport pickle\\n\\nword_index = pickle.load(open('word_index.pkl', 'rb'))\\n\""
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "%%time\n",
    "\n",
    "import pickle\n",
    "\n",
    "word_index = pickle.load(open('word_index.pkl', 'rb'))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "_uuid": "2801e906d9eb5bc96c231cf1e3d577a160d8d289",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "YfAhNjEJEXmN",
    "outputId": "58618a30-4fab-44f0-8dec-591a8df2da47"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glove:\n",
      "Loading embeddings from: ../input/embeddings/glove.840B.300d/glove.840B.300d.txt\n",
      "Found 2195892 word vectors.\n",
      "Found embeddings for 63.10% of vocab\n",
      "Found embeddings for  99.39% of all text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:2: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 47s, sys: 7.6 s, total: 2min 55s\n",
      "Wall time: 2min 51s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import gc\n",
    "\n",
    "print('glove:')\n",
    "glove_path = '../input/embeddings/glove.840B.300d/glove.840B.300d.txt'\n",
    "embeddings_index = loadEmbeddings(glove_path, EMBEDDING_DIM)\n",
    "check_coverage(vocab, embeddings_index)\n",
    "embedding_matrix = getEmbeddingMatrix(embeddings_index, word_index)\n",
    "del embeddings_index\n",
    "gc.collect()\n",
    "np.save('glove.npy', embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "889bc1ae4af9fe032c72e8c8c606ae5b1d66f7d8",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "YfAhNjEJEXmN",
    "outputId": "58618a30-4fab-44f0-8dec-591a8df2da47"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "paragram:\n",
      "Loading embeddings from: ../input/embeddings/paragram_300_sl999/paragram_300_sl999.txt\n"
     ]
    }
   ],
   "source": [
    "print('paragram:')\n",
    "paragram_path = '../input/embeddings/paragram_300_sl999/paragram_300_sl999.txt'\n",
    "embeddings_index = loadEmbeddings(paragram_path, EMBEDDING_DIM, encoding='utf8', errors='ignore')\n",
    "check_coverage(vocab, embeddings_index)\n",
    "embedding_matrix = getEmbeddingMatrix(embeddings_index, word_index)\n",
    "del embeddings_index\n",
    "gc.collect()\n",
    "np.save('paragram.npy', embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "79b0a76992718f29aec733bec9f59beb85302a31",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "YfAhNjEJEXmN",
    "outputId": "58618a30-4fab-44f0-8dec-591a8df2da47"
   },
   "outputs": [],
   "source": [
    "print('wiki:')\n",
    "wiki_path = '../input/embeddings/wiki-news-300d-1M/wiki-news-300d-1M.vec'\n",
    "embeddings_index = loadEmbeddings(wiki_path, EMBEDDING_DIM)\n",
    "check_coverage(vocab, embeddings_index)\n",
    "embedding_matrix = getEmbeddingMatrix(embeddings_index, word_index)\n",
    "del embeddings_index\n",
    "gc.collect()\n",
    "np.save('wiki.npy', embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c1ec208ac42fbf73e8213442f1333cbf18791a16"
   },
   "outputs": [],
   "source": [
    "print('google_news:')\n",
    "google_news_path = '../input/embeddings/GoogleNews-vectors-negative300/GoogleNews-vectors-negative300.bin'\n",
    "embeddings_index = loadEmbeddingsGensim(google_news_path, EMBEDDING_DIM)\n",
    "check_coverage(vocab, embeddings_index)\n",
    "embedding_matrix = getEmbeddingMatrix(embeddings_index, word_index)\n",
    "del embeddings_index\n",
    "gc.collect()\n",
    "np.save('google_news.npy', embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7711de071093e6c256b2e8bf68fe64e9436ba0e2"
   },
   "outputs": [],
   "source": [
    "del word_index\n",
    "del vocab\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "380e34c9a8b4a797b10cb54e15760a9dd7b28ae0",
    "colab_type": "text",
    "id": "BUSd8dmWEUf4"
   },
   "source": [
    "# Oversample training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "47c26457a2b8c17015bf5c5c60cbb562fe199429"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "sm = SMOTE(random_state=42, ratio = 1.0)\n",
    "X_train, y_train = sm.fit_sample(X_train, y_train)\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f28b53680bc8874337b09a61887d6c74da683659"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "balanced_train_df = pd.DataFrame()\n",
    "balanced_train_df[0] = np.array(y_train)\n",
    "\n",
    "target_ratios = balanced_train_df[0].value_counts(normalize=True)\n",
    "\n",
    "print(target_ratios)\n",
    "\n",
    "target_ratios.plot(kind='bar', title='Ratios after SMOTE (target)')\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "fab17b9cec7b6c69d9b96bfc5731882a1216d788",
    "colab_type": "text",
    "id": "aNd1KcNjsvxj"
   },
   "source": [
    "# Setup model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aNd1KcNjsvxj"
   },
   "source": [
    "# Restore point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "test_df = pd.read_pickle('test_df.pkl')\n",
    "\n",
    "X_train = np.load('X_train.npy')\n",
    "X_test = np.load('X_test.npy')\n",
    "y_train = pd.read_pickle('y_train.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d45a12e7532c1ff87d68b626baada8a5bbe6b0fe",
    "colab_type": "text",
    "id": "BUSd8dmWEUf4"
   },
   "source": [
    "## Embeddings Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "48576619ba4f1847df5ea12bdd11b24b3920b25d"
   },
   "outputs": [],
   "source": [
    "from keras.layers import Embedding\n",
    "\n",
    "embedding_layers = {}\n",
    "\n",
    "embedding_matrix = np.load('glove.npy')\n",
    "embedding_layers['glove'] = Embedding(MAX_WORDS, EMBEDDING_DIM, weights=[embedding_matrix], input_length=MAX_SEQUENCE_LENGTH, trainable=True)\n",
    "\n",
    "embedding_matrix = np.load('paragram.npy')\n",
    "embedding_layers['paragram'] = Embedding(MAX_WORDS, EMBEDDING_DIM, weights=[embedding_matrix], input_length=MAX_SEQUENCE_LENGTH, trainable=True)\n",
    "\n",
    "embedding_matrix = np.load('wiki.npy')\n",
    "embedding_layers['wiki'] = Embedding(MAX_WORDS, EMBEDDING_DIM, weights=[embedding_matrix], input_length=MAX_SEQUENCE_LENGTH, trainable=True)\n",
    "\n",
    "embedding_matrix = np.load('google_news.npy')\n",
    "embedding_layers['google_news'] = Embedding(MAX_WORDS, EMBEDDING_DIM, weights=[embedding_matrix], input_length=MAX_SEQUENCE_LENGTH, trainable=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "60a8b6ecb457fff127b4f7db954c42c63fa68b76",
    "colab_type": "text",
    "id": "BUSd8dmWEUf4"
   },
   "source": [
    "## NN: Bidirectional GRU per embedding with concactenation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2d9a7a2733cee240d25312c05c08d41e0d6c4976"
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "from keras.layers import Dense, Dropout, Input, GlobalMaxPool1D\n",
    "from keras.layers import Conv1D, MaxPooling1D, Embedding, Bidirectional\n",
    "from keras.layers import Activation, BatchNormalization, CuDNNGRU\n",
    "from keras.layers import SpatialDropout1D, Concatenate, Flatten, Reshape\n",
    "from keras.regularizers import l2\n",
    "from keras.models import Model\n",
    "\n",
    "\n",
    "inp = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "\n",
    "a = embedding_layers['glove'] (inp)\n",
    "a = Bidirectional(CuDNNGRU(64, return_sequences=True))(a)\n",
    "a = BatchNormalization()(a)\n",
    "a = GlobalMaxPool1D()(a)\n",
    "a = Dense(16, kernel_regularizer=l2(0.01), use_bias=False)(a)\n",
    "a = BatchNormalization()(a)\n",
    "a = Activation(\"relu\")(a)\n",
    "a = Dropout(0.1)(a)\n",
    "\n",
    "b = embedding_layers['paragram'] (inp)\n",
    "b = Bidirectional(CuDNNGRU(64, return_sequences=True))(b)\n",
    "b = BatchNormalization()(b)\n",
    "b = GlobalMaxPool1D()(b)\n",
    "b = Dense(16, kernel_regularizer=l2(0.01), use_bias=False)(b)\n",
    "b = BatchNormalization()(b)\n",
    "b = Activation(\"relu\")(b)\n",
    "b = Dropout(0.1)(b)\n",
    "\n",
    "c = embedding_layers['wiki'] (inp)\n",
    "c = Bidirectional(CuDNNGRU(64, return_sequences=True))(c)\n",
    "c = BatchNormalization()(c)\n",
    "c = GlobalMaxPool1D()(c)\n",
    "c = Dense(16, kernel_regularizer=l2(0.01), use_bias=False)(c)\n",
    "c = BatchNormalization()(c)\n",
    "c = Activation(\"relu\")(c)\n",
    "c = Dropout(0.1)(c)\n",
    "\n",
    "d = embedding_layers['google_news'] (inp)\n",
    "d = Bidirectional(CuDNNGRU(64, return_sequences=True))(d)\n",
    "d = BatchNormalization()(d)\n",
    "d = GlobalMaxPool1D()(d)\n",
    "d = Dense(16, kernel_regularizer=l2(0.01), use_bias=False)(d)\n",
    "d = BatchNormalization()(d)\n",
    "d = Activation(\"relu\")(d)\n",
    "d = Dropout(0.1)(d)\n",
    "\n",
    "x = Concatenate(axis=1)([a, b, c, d])\n",
    "x = Dense(32, kernel_regularizer=l2(0.01), use_bias=False)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation(\"relu\")(x)\n",
    "x = Dense(1, use_bias=False)(x)\n",
    "x = BatchNormalization()(x)\n",
    "out = Activation(\"sigmoid\")(x)\n",
    "\n",
    "model = Model(inp, out)\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    " \n",
    "def f1(y_true, y_pred):\n",
    "    p = precision(y_true, y_pred)\n",
    "    r = recall(y_true, y_pred)\n",
    "    return 2*((p*r)/(p+r+K.epsilon()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "74e7edd06d9d1ef89f4369021b8ce094be9e21db",
    "colab_type": "text",
    "id": "Lp4o2h9Fs8gP"
   },
   "source": [
    "# Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "fafbbea8029e31d17a3f731639bbc62970e4e1b0",
    "colab": {},
    "colab_type": "code",
    "id": "L75Rc0Gqtclm"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy', f1, recall, precision])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NVFKqCPUtJcy"
   },
   "source": [
    "# serialize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model.h5')\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aNd1KcNjsvxj"
   },
   "source": [
    "# Setup f1-score, precision and recall metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "checkpoints = ModelCheckpoint(MODEL_VERSION + '.weights_checkpoint.h5', monitor=\"val_f1\", mode=\"max\", verbose=True, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "from keras.callbacks import Callback\n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score, precision_recall_fscore_support\n",
    "\n",
    "class Metrics(Callback):\n",
    "\n",
    "\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.val_f1s = []\n",
    "        self.val_recalls = []\n",
    "        self.val_precisions = []\n",
    " \n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        val_predict = (np.asarray(self.model.predict(self.validation_data[0]))).round()\n",
    "        val_targ = self.validation_data[1]\n",
    "        _val_precision, _val_recall, _val_f1, _ = precision_recall_fscore_support(val_targ, val_predict, average='binary')\n",
    "        self.val_f1s.append(_val_f1)\n",
    "        self.val_recalls.append(_val_recall)\n",
    "        self.val_precisions.append(_val_precision)\n",
    "        print(\" — val_f1: %f — val_precision: %f — val_recall: %f\" %(_val_f1, _val_precision, _val_recall))\n",
    "        return\n",
    "\n",
    "metrics = Metrics()\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "21e24633c2528b71fc434bf528f7b29fbed63f25",
    "colab_type": "text",
    "id": "QIn-67cmvDFk"
   },
   "source": [
    "## Split train/validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3a4e4292f236ac2a779968bb38239e61e5f48eab"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, train_size=0.8,\n",
    "                                              random_state=233)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1d1c4d092bca6f093254b5792c4b8801c1282b0f",
    "colab_type": "text",
    "id": "NVFKqCPUtJcy"
   },
   "source": [
    "# Train the model\n",
    "\n",
    "Use model checkpointing to save the model that attains the best validation loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2db478168d542638ce5cb6358de7ebd503d000b0",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "3OwX8ErsteZL",
    "outputId": "f718108c-5f78-4d9b-8814-c7044a9cce96"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "hist = model.fit(X_train, y_train, validation_data=(X_val, y_val), callbacks=[checkpoints], epochs=2, batch_size=256)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "926710a7b8364a65a6ea5bdb8f103462b622549c",
    "colab_type": "text",
    "id": "NVFKqCPUtJcy"
   },
   "source": [
    "# Predict validation labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "80dbd1aae9b5ec74071b7a11de96abee7cd2ad66"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "pred_val = model.predict([X_val], batch_size=1024, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "fbe1a9626a625a4540b35fe646af0d78e8952b24",
    "colab_type": "text",
    "id": "NVFKqCPUtJcy"
   },
   "source": [
    "# Find optimal threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c5861eb15765c20d4a5be5892543520bdb006bfa"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "\n",
    "def optimalThreshold(y_true,y_pred):\n",
    "    idx = 0\n",
    "    cur_f1 = 0\n",
    "    cur_prec = 0\n",
    "    cur_recall = 0\n",
    "    max_f1 = 0\n",
    "    thres = 0\n",
    "    for idx in np.arange(0.1, 0.501, 0.01):\n",
    "        cur_f1 = f1_score(y_true, np.array(y_pred)> idx)\n",
    "        cur_recall = recall_score(y_true, np.array(y_pred)> idx)\n",
    "        cur_prec = precision_score(y_true, np.array(y_pred)> idx)\n",
    "        print('Current threshold is {:.4f} with F1 score: {:.4f}, Recall score: {:.4f}, Precision score: {:.4f}'\n",
    "              .format(idx, cur_f1, cur_recall, cur_prec)\n",
    "             )\n",
    "        if cur_f1 > max_f1:\n",
    "            max_f1 = cur_f1\n",
    "            thres = idx\n",
    "    print('optimal threshold is {:.4f} with F1 score: {:.4f}'.format(thres, max_f1))\n",
    "    return thres\n",
    "threshold = optimalThreshold(y_val,pred_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "print(classification_report(y_val, np.array(pred_val > threshold).astype(int), target_names=['sincere', 'insincere']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "cm = confusion_matrix(y_val, np.array(pred_val > threshold).astype(int))\n",
    "ax = plt.subplot()\n",
    "hm = sns.heatmap(cm, annot=True, ax = ax, fmt='g', \n",
    "                 cmap=ListedColormap(['white']), linecolor='black', \n",
    "                 linewidth=1, cbar=False,\n",
    "                 xticklabels = 1, yticklabels = 1 )\n",
    "\n",
    "\n",
    "# labels, title and ticks\n",
    "ax.set_xlabel('Predicted labels')\n",
    "ax.set_ylabel('True labels') \n",
    "ax.set_title('Confusion Matrix')\n",
    "ax.xaxis.set_ticklabels(['sincere', 'insincere'])\n",
    "ax.yaxis.set_ticklabels(['sincere', 'insincere'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0ff585d4c11ae673051881795e74ff97d8d2b4c8"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "plt.title('model accuracy')\n",
    "plt.plot(hist.history['acc'])\n",
    "plt.plot(hist.history['val_acc'])\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0ff585d4c11ae673051881795e74ff97d8d2b4c8"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "plt.title('model loss')\n",
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0ff585d4c11ae673051881795e74ff97d8d2b4c8"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "plt.title('model F1-score')\n",
    "plt.plot(hist.history['f1'])\n",
    "plt.plot(hist.history['val_f1'])\n",
    "plt.ylabel('f1 score')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d377f47a86a67e1b60bf83efa2e85c08e87281dd",
    "colab_type": "text",
    "id": "NVFKqCPUtJcy"
   },
   "source": [
    "# Predict test labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0670f1a7c1ed5cfd85d049dfc0ef1681aaab055b"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "pred_test = model.predict([X_test], batch_size=1024, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f3c1ff0ac4324bbf847ed3fdafe4db682d833f8a",
    "colab_type": "text",
    "id": "NVFKqCPUtJcy"
   },
   "source": [
    "# Prepare submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7f3601299112b7d1ea815db80243344ace06ca42"
   },
   "outputs": [],
   "source": [
    "submission_df = pd.DataFrame({\"qid\":test_df[\"qid\"].values})\n",
    "submission_df['prediction'] = (pred_test > threshold).astype(int)\n",
    "submission_df.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "\n",
    "pickle_out = open(MODEL_VERSION + '.hist.pkl',\"wb\")\n",
    "pickle.dump(hist, pickle_out)\n",
    "pickle_out.close()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "capstone.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
