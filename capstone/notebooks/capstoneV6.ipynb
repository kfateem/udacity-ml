{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "749cb0b7d343d12569698ece840039c7fef54711",
    "colab_type": "text",
    "id": "BUSd8dmWEUf4"
   },
   "source": [
    "# Capstone V6 model\n",
    "\n",
    "Fork from V3.\n",
    "\n",
    "The same model as capstoneV3 but only 2 epochs and no class weights.\n",
    "\n",
    "The validation F1-score is {} at a threshold of {}."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "85c12f788178232533cbf7f141e217c32b882cda",
    "colab_type": "text",
    "id": "w7oagxHHofxb"
   },
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "f0421d98769ce1b3bcc0b65f729851be0d275cb5"
   },
   "outputs": [],
   "source": [
    "MODEL_VERSION = 'capstoneV6'\n",
    "MAX_SEQUENCE_LENGTH = 100\n",
    "EMBEDDING_DIM = 300\n",
    "MAX_WORDS = 50000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "749cb0b7d343d12569698ece840039c7fef54711",
    "colab_type": "text",
    "id": "BUSd8dmWEUf4"
   },
   "source": [
    "## Common english contraction mappings (wikipedia):\n",
    "https://en.wikipedia.org/wiki/Wikipedia:List_of_English_contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "d5a645a8f6a9f70d9db108cebbc683089e548260"
   },
   "outputs": [],
   "source": [
    "CONTRACTION_MAPPING = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\", \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\", \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",  \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\", \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\", \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\", \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\", \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\", \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\", \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\", \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\", \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\", \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\", \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\", \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\", \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",  \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\", \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\", \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\", \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\", \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\", \"you're\": \"you are\", \"you've\": \"you have\" }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "56282f6e5433223f3823e24e95fe170534e8dcae"
   },
   "outputs": [],
   "source": [
    "PUNCT = \"/-'?!.,#$%\\'()*+-/:;<=>@[\\\\]^_`{|}~\" + '\"\"“”’' + '∞θ÷α•à−β∅³π‘₹´°£€\\×™√²—–&'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "a2a79c0d80f797d3868fac83217b1e2479bee8dc"
   },
   "outputs": [],
   "source": [
    "SPECIAL_PUNCT = {'\\u200b': ' ', '…': ' ... ', '\\ufeff': '', 'करना': '', 'है': ''}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "451df1dd80192c375340a023e852cab39698d434"
   },
   "outputs": [],
   "source": [
    "PUNCT_MAPPING = {\"‘\": \"'\", \"₹\": \"e\", \"´\": \"'\", \"°\": \"\", \"€\": \"e\", \"™\": \"tm\", \"√\": \" sqrt \", \"×\": \"x\", \"²\": \"2\", \"—\": \"-\", \"–\": \"-\", \"’\": \"'\", \"_\": \"-\", \"`\": \"'\", '“': '\"', '”': '\"', '“': '\"', \"£\": \"e\", '∞': 'infinity', 'θ': 'theta', '÷': '/', 'α': 'alpha', '•': '.', 'à': 'a', '−': '-', 'β': 'beta', '∅': '', '³': '3', 'π': 'pi', }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "228dc3ca14b0b0af33d6c874400d8f01ef96a874"
   },
   "outputs": [],
   "source": [
    "MISPELL_MAPPING = {'colour': 'color', 'centre': 'center', 'favourite': 'favorite', 'travelling': 'traveling', 'counselling': 'counseling', 'theatre': 'theater', 'cancelled': 'canceled', 'labour': 'labor', 'organisation': 'organization', 'wwii': 'world war 2', 'citicise': 'criticize', 'youtu ': 'youtube ', 'Qoura': 'Quora', 'sallary': 'salary', 'Whta': 'What', 'narcisist': 'narcissist', 'howdo': 'how do', 'whatare': 'what are', 'howcan': 'how can', 'howmuch': 'how much', 'howmany': 'how many', 'whydo': 'why do', 'doI': 'do I', 'theBest': 'the best', 'howdoes': 'how does', 'mastrubation': 'masturbation', 'mastrubate': 'masturbate', \"mastrubating\": 'masturbating', 'pennis': 'penis', 'Etherium': 'Ethereum', 'narcissit': 'narcissist', 'bigdata': 'big data', '2k17': '2017', '2k18': '2018', 'qouta': 'quota', 'exboyfriend': 'ex boyfriend', 'airhostess': 'air hostess', \"whst\": 'what', 'watsapp': 'whatsapp', 'demonitisation': 'demonetization', 'demonitization': 'demonetization', 'demonetisation': 'demonetization', 'pokémon': 'pokemon'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "974ca8fb2157648f2ace9c41bf37e0d87dd2eb20",
    "colab_type": "text",
    "id": "w7oagxHHofxb"
   },
   "source": [
    "# Helpers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "408f2ecb4a7380c2a57635996ca248020e4aaa94",
    "colab_type": "text",
    "id": "BUSd8dmWEUf4"
   },
   "source": [
    "## Embedding helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "88880adc1b1e2ca67e77db81d36165fad52d9e1c"
   },
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def loadEmbeddings(path, dimensions, mode='r', encoding=None, errors=None):\n",
    "    print('Loading embeddings from: %s' %path)\n",
    "    embeddings = {}\n",
    "    f = open(path, buffering=((2<<16) + 8), mode=mode, encoding=encoding, errors=errors)\n",
    "    for line in f:\n",
    "        if len(line) <= 100:\n",
    "            continue\n",
    "        values = line.split()\n",
    "        word = ''.join(values[:-dimensions])\n",
    "        coefs = np.asarray(values[-dimensions:], dtype='float32')\n",
    "        embeddings[word] = coefs\n",
    "    f.close()\n",
    "    print('Found %s word vectors.' % len(embeddings))\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "1f202cf2766c8d2a73834f057bd195928136ce1b"
   },
   "outputs": [],
   "source": [
    "def loadEmbeddingsGensim(path, dimensions, binary=True):\n",
    "    print('Loading embeddings from: %s' %path)\n",
    "    embeddings = {}\n",
    "    gensim_vecs = KeyedVectors.load_word2vec_format(path, binary=binary)\n",
    "    for word, vector in zip(gensim_vecs.vocab, gensim_vecs.vectors):\n",
    "        coefs = np.asarray(vector[-dimensions:], dtype='float32')\n",
    "        embeddings[word] = coefs\n",
    "    print('Found %s word vectors.' % len(embeddings))\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "344bdbebf5757946836407ee4a0a8ace39b65228",
    "colab": {},
    "colab_type": "code",
    "id": "0KeJJofUpQm9"
   },
   "outputs": [],
   "source": [
    "def getEmbeddingMatrix(embedding, word_index):\n",
    "    all_embs = np.stack(embedding.values())\n",
    "    emb_mean,emb_std = all_embs.mean(), all_embs.std()\n",
    "    embed_size = all_embs.shape[1]\n",
    "    \n",
    "    nb_words = min(MAX_WORDS, len(word_index))\n",
    "    embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embed_size))\n",
    "    for word, i in word_index.items():\n",
    "        if i >= MAX_WORDS:\n",
    "            continue\n",
    "        embedding_vector = embedding.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "    \n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e462ed6a5cd6b481db42664c68c3451b61026d76",
    "colab_type": "text",
    "id": "BUSd8dmWEUf4"
   },
   "source": [
    "### Helper to replace contractions in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "e9cd4f331303cea868030ed771c30c01a65f74a7"
   },
   "outputs": [],
   "source": [
    "def clean_contractions(text):\n",
    "    specials = [\"’\", \"‘\", \"´\", \"`\"]\n",
    "    for s in specials:\n",
    "        text = text.replace(s, \"'\")\n",
    "    text = ' '.join([CONTRACTION_MAPPING[t] if t in CONTRACTION_MAPPING else t for t in text.split(\" \")])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4d9fd63b54dda11ec562c8e2c85fa386e9910958",
    "colab_type": "text",
    "id": "BUSd8dmWEUf4"
   },
   "source": [
    "### Helper to remap punctuations in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "c1b038b3cadf6c09fcb2523a1171ad8e95a1700d"
   },
   "outputs": [],
   "source": [
    "def clean_special_chars(text):\n",
    "    for p in PUNCT_MAPPING:\n",
    "        text = text.replace(p, PUNCT_MAPPING[p])\n",
    "    \n",
    "    for p in PUNCT:\n",
    "        text = text.replace(p, ' ' + p + ' ')\n",
    "    \n",
    "    for s in SPECIAL_PUNCT:\n",
    "        text = text.replace(s, SPECIAL_PUNCT[s])\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "dbcf585e91cd7faad3c230d6eb191dc39695db17",
    "colab_type": "text",
    "id": "BUSd8dmWEUf4"
   },
   "source": [
    "### Helper to correct common mispellings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "186bf0c75630a56d02120c197712e4fb5681ad8d"
   },
   "outputs": [],
   "source": [
    "def correct_spelling(x):\n",
    "    for word in MISPELL_MAPPING.keys():\n",
    "        x = x.replace(word, MISPELL_MAPPING[word])\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "92cc1a4a5777c338f819adde4ec455d9856013dc",
    "colab_type": "text",
    "id": "BUSd8dmWEUf4"
   },
   "source": [
    "## Coverage helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "20732a275083041d5a06ad4bd6a7938f7333afda"
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def build_vocab(texts):\n",
    "    sentences = texts.apply(lambda x: x.split()).values\n",
    "    vocab = Counter()\n",
    "    for sentence in sentences:\n",
    "        for word in sentence:\n",
    "            vocab[word] += 1\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "b83aab607f791f5824b3eca4277741950cd36d92"
   },
   "outputs": [],
   "source": [
    "import operator\n",
    "\n",
    "def check_coverage(vocab, embeddings_index):\n",
    "    known_words = {}\n",
    "    unknown_words = {}\n",
    "    nb_known_words = 0\n",
    "    nb_unknown_words = 0\n",
    "    for word in vocab.keys():\n",
    "        try:\n",
    "            known_words[word] = embeddings_index[word]\n",
    "            nb_known_words += vocab[word]\n",
    "        except:\n",
    "            unknown_words[word] = vocab[word]\n",
    "            nb_unknown_words += vocab[word]\n",
    "            pass\n",
    "\n",
    "    print('Found embeddings for {:.2%} of vocab'.format(len(known_words) / len(vocab)))\n",
    "    print('Found embeddings for  {:.2%} of all text'.format(nb_known_words / (nb_known_words + nb_unknown_words)))\n",
    "    unknown_words = sorted(unknown_words.items(), key=operator.itemgetter(1))[::-1]\n",
    "\n",
    "    return unknown_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "70e187637082e5f448863c5f965fff8ab80ed065",
    "colab_type": "text",
    "id": "w7oagxHHofxb"
   },
   "source": [
    "# Import test/train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_uuid": "e20e43f9ea433ee2eee88003355ef86f724fa01c",
    "colab": {},
    "colab_type": "code",
    "id": "X3n8bRW6WcKo"
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"../input/train.csv\")\n",
    "test_df = pd.read_csv(\"../input/test.csv\")\n",
    "\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.max_rows = None\n",
    "pd.options.display.max_colwidth = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2052ad18f26ea6c28d4feeaac402d61438a6f1cf",
    "colab_type": "text",
    "id": "w7oagxHHofxb"
   },
   "source": [
    "# Analyze train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_uuid": "8f55a111d1222a541a6cc5938de12577b3b12215",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 393
    },
    "colab_type": "code",
    "id": "h0aRi6Toaq8j",
    "outputId": "5d5c6246-c8c3-49e0-e8b7-58850a83f62f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample insincere questions\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>question_text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1289561</th>\n",
       "      <td>fcbcf8ca61c9d7adf5c6</td>\n",
       "      <td>What is the minimum amount of advanced abstract demagoguery one must master before being allowed to grow a beard, wear glasses and carry a Macbook into an indie coffee shop?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>715940</th>\n",
       "      <td>8c2684314da3be6e201f</td>\n",
       "      <td>\"Your answer has been collapsed\" you can improve it (make it more liberal) if you actually want people to see it. no thanks?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146560</th>\n",
       "      <td>1caa8decef4bfda24a30</td>\n",
       "      <td>Is it true that Chinese Dna have dog genes and goldfish genes?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1203475</th>\n",
       "      <td>ebe1fab411658d8f95a8</td>\n",
       "      <td>Has MS-13 infiltrated the Democratic Party?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588363</th>\n",
       "      <td>7340d0a10bb54805002d</td>\n",
       "      <td>How do I unsubscribe to your shit?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890351</th>\n",
       "      <td>ae6e46c1200874b694af</td>\n",
       "      <td>Why is Feb. 10, 0600 the God-Humanity Covenant Day?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010553</th>\n",
       "      <td>c605237a8c95dfc9a566</td>\n",
       "      <td>Why is it okay to lock Tommy Robinson up for speaking his mind on the UK pedophile grooming gangs?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>864465</th>\n",
       "      <td>a962287b3d485d98425c</td>\n",
       "      <td>Can an Arab man make love with a Jewish woman?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1096992</th>\n",
       "      <td>d6ff9ad62e139171d1e4</td>\n",
       "      <td>When can we send all Muslims to Pakistan?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61353</th>\n",
       "      <td>0c0da3e9983d892364d2</td>\n",
       "      <td>I want to make a virtual heaven where everyone will get uploaded when they die in physical life so their soul stays alive forever. But how can I retrieve the souls of people who are long gone?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          qid  \\\n",
       "1289561  fcbcf8ca61c9d7adf5c6   \n",
       "715940   8c2684314da3be6e201f   \n",
       "146560   1caa8decef4bfda24a30   \n",
       "1203475  ebe1fab411658d8f95a8   \n",
       "588363   7340d0a10bb54805002d   \n",
       "890351   ae6e46c1200874b694af   \n",
       "1010553  c605237a8c95dfc9a566   \n",
       "864465   a962287b3d485d98425c   \n",
       "1096992  d6ff9ad62e139171d1e4   \n",
       "61353    0c0da3e9983d892364d2   \n",
       "\n",
       "                                                                                                                                                                                            question_text  \\\n",
       "1289561  What is the minimum amount of advanced abstract demagoguery one must master before being allowed to grow a beard, wear glasses and carry a Macbook into an indie coffee shop?                      \n",
       "715940   \"Your answer has been collapsed\" you can improve it (make it more liberal) if you actually want people to see it. no thanks?                                                                       \n",
       "146560   Is it true that Chinese Dna have dog genes and goldfish genes?                                                                                                                                     \n",
       "1203475  Has MS-13 infiltrated the Democratic Party?                                                                                                                                                        \n",
       "588363   How do I unsubscribe to your shit?                                                                                                                                                                 \n",
       "890351   Why is Feb. 10, 0600 the God-Humanity Covenant Day?                                                                                                                                                \n",
       "1010553  Why is it okay to lock Tommy Robinson up for speaking his mind on the UK pedophile grooming gangs?                                                                                                 \n",
       "864465   Can an Arab man make love with a Jewish woman?                                                                                                                                                     \n",
       "1096992  When can we send all Muslims to Pakistan?                                                                                                                                                          \n",
       "61353    I want to make a virtual heaven where everyone will get uploaded when they die in physical life so their soul stays alive forever. But how can I retrieve the souls of people who are long gone?   \n",
       "\n",
       "         target  \n",
       "1289561  1       \n",
       "715940   1       \n",
       "146560   1       \n",
       "1203475  1       \n",
       "588363   1       \n",
       "890351   1       \n",
       "1010553  1       \n",
       "864465   1       \n",
       "1096992  1       \n",
       "61353    1       "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Sample insincere questions\")\n",
    "train_df.loc[train_df['target'] == 1].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_uuid": "73bd9f42266c6c2184ff65017ccb5f62e38314f5",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 376
    },
    "colab_type": "code",
    "id": "n_mslOIdaj8G",
    "outputId": "c0c9da0b-96d8-436f-fe37-28a2da1d6b69"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample sincere questions\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>question_text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>445813</th>\n",
       "      <td>575715882de430d6c004</td>\n",
       "      <td>What makes a great guest?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597000</th>\n",
       "      <td>74ef07aa3b15cd3ef11e</td>\n",
       "      <td>What are the health benefits of doing the South Beach Diet for weight loss purposes?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133548</th>\n",
       "      <td>1a22764e4d74df1491fa</td>\n",
       "      <td>What can we do to preserve the American black bear's habitat in the northern forests of America?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566391</th>\n",
       "      <td>6ef96d85466f9e5515af</td>\n",
       "      <td>What are the best universities for MS for instrumentation &amp; control field and what are the deadlines to apply for Fall 18?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>869092</th>\n",
       "      <td>aa4802db7b0607a245a9</td>\n",
       "      <td>Why does the U.S. not allow re-trials even if new evidence is found?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>661084</th>\n",
       "      <td>817dc9f703b155f4d107</td>\n",
       "      <td>Which is the movie where the rapist has been captured and kept in a cellar by the victim's parent for years? This is revealed in the end scene.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686324</th>\n",
       "      <td>866b88589de6662b2ae6</td>\n",
       "      <td>How is the compound of nitrogen and oxygen determined?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>616890</th>\n",
       "      <td>78cd6842e567a2038bcc</td>\n",
       "      <td>What are the characteristics of the plantation system?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406973</th>\n",
       "      <td>4fbe93ac72e9ecff69c7</td>\n",
       "      <td>What are the views of Dr Awadhesh Singh on Rajiv Dixit?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>903590</th>\n",
       "      <td>b10fa062adc1f39c0505</td>\n",
       "      <td>How does mathematics help in medical science?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         qid  \\\n",
       "445813  575715882de430d6c004   \n",
       "597000  74ef07aa3b15cd3ef11e   \n",
       "133548  1a22764e4d74df1491fa   \n",
       "566391  6ef96d85466f9e5515af   \n",
       "869092  aa4802db7b0607a245a9   \n",
       "661084  817dc9f703b155f4d107   \n",
       "686324  866b88589de6662b2ae6   \n",
       "616890  78cd6842e567a2038bcc   \n",
       "406973  4fbe93ac72e9ecff69c7   \n",
       "903590  b10fa062adc1f39c0505   \n",
       "\n",
       "                                                                                                                                          question_text  \\\n",
       "445813  What makes a great guest?                                                                                                                         \n",
       "597000  What are the health benefits of doing the South Beach Diet for weight loss purposes?                                                              \n",
       "133548  What can we do to preserve the American black bear's habitat in the northern forests of America?                                                  \n",
       "566391  What are the best universities for MS for instrumentation & control field and what are the deadlines to apply for Fall 18?                        \n",
       "869092  Why does the U.S. not allow re-trials even if new evidence is found?                                                                              \n",
       "661084  Which is the movie where the rapist has been captured and kept in a cellar by the victim's parent for years? This is revealed in the end scene.   \n",
       "686324  How is the compound of nitrogen and oxygen determined?                                                                                            \n",
       "616890  What are the characteristics of the plantation system?                                                                                            \n",
       "406973  What are the views of Dr Awadhesh Singh on Rajiv Dixit?                                                                                           \n",
       "903590  How does mathematics help in medical science?                                                                                                     \n",
       "\n",
       "        target  \n",
       "445813  0       \n",
       "597000  0       \n",
       "133548  0       \n",
       "566391  0       \n",
       "869092  0       \n",
       "661084  0       \n",
       "686324  0       \n",
       "616890  0       \n",
       "406973  0       \n",
       "903590  0       "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Sample sincere questions\")\n",
    "train_df.loc[train_df['target'] == 0].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_uuid": "7b8a948c3ae97a09decf8f0a6fadff9eed5f83b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.93813\n",
      "1    0.06187\n",
      "Name: target, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "target_ratios = train_df.target.value_counts(normalize=True)\n",
    "\n",
    "print(target_ratios)\n",
    "\n",
    "target_ratios.plot(kind='bar', title='Ratios (target)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_uuid": "323d3c4ed532d94120a8681d822c5ad60fc6abae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average word length of questions in train is 13.\n",
      "Average word length of questions in test is 13.\n"
     ]
    }
   ],
   "source": [
    "print('Average word length of questions in train is {0:.0f}.'.format(np.mean(train_df['question_text'].apply(lambda x: len(x.split())))))\n",
    "print('Average word length of questions in test is {0:.0f}.'.format(np.mean(test_df['question_text'].apply(lambda x: len(x.split())))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_uuid": "3b49c4e9bbe8ab8ccddfc8b9c8b24bcafe1bbd3c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max word length of questions in train is 134.\n",
      "Max word length of questions in test is 87.\n"
     ]
    }
   ],
   "source": [
    "print('Max word length of questions in train is {0:.0f}.'.format(np.max(train_df['question_text'].apply(lambda x: len(x.split())))))\n",
    "print('Max word length of questions in test is {0:.0f}.'.format(np.max(test_df['question_text'].apply(lambda x: len(x.split())))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_uuid": "83ede400076de1e67b90de70553ae273d0b16473"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average character length of questions in train is 71.\n",
      "Average character length of questions in test is 70.\n"
     ]
    }
   ],
   "source": [
    "print('Average character length of questions in train is {0:.0f}.'.format(np.mean(train_df['question_text'].apply(lambda x: len(x)))))\n",
    "print('Average character length of questions in test is {0:.0f}.'.format(np.mean(test_df['question_text'].apply(lambda x: len(x)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_uuid": "1b66752d7dfea96b9c5b171edfe6f6d2831956a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max character length of questions in train is 1017.\n",
      "Max character length of questions in test is 588.\n"
     ]
    }
   ],
   "source": [
    "print('Max character length of questions in train is {0:.0f}.'.format(np.max(train_df['question_text'].apply(lambda x: len(x)))))\n",
    "print('Max character length of questions in test is {0:.0f}.'.format(np.max(test_df['question_text'].apply(lambda x: len(x)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "_uuid": "5ff56f79415f02f3a029a2a12c40444410427763"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p999 character length of questions in train is 249.\n",
      "p999 character length of questions in test is 249.\n"
     ]
    }
   ],
   "source": [
    "print('p999 character length of questions in train is {0:.0f}.'.format(np.percentile(train_df['question_text'].apply(lambda x: len(x)), 99.9)))\n",
    "print('p999 character length of questions in test is {0:.0f}.'.format(np.percentile(test_df['question_text'].apply(lambda x: len(x)), 99.9)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "755dc21b8d2ad16d4711e5f3cfc664617fba4a3f",
    "colab_type": "text",
    "id": "QIn-67cmvDFk"
   },
   "source": [
    "# Data processing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e32a7c365a4f71149537c44eca72b762c0cf1a8b",
    "colab_type": "text",
    "id": "QIn-67cmvDFk"
   },
   "source": [
    "## TODO: Feature engineering\n",
    "\n",
    "Add feature engineering here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "_uuid": "a65029f02944902ad1c4a3b988ba4d166ce26910"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 48.7 s, sys: 304 ms, total: 49 s\n",
      "Wall time: 49 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "train_df['treated_question'] = train_df['question_text'].apply(lambda x: x.lower())\n",
    "train_df['treated_question'] = train_df['treated_question'].apply(lambda x: clean_contractions(x))\n",
    "train_df['treated_question'] = train_df['treated_question'].apply(lambda x: clean_special_chars(x))\n",
    "train_df['treated_question'] = train_df['treated_question'].apply(lambda x: correct_spelling(x))\n",
    "\n",
    "test_df['treated_question'] = test_df['question_text'].apply(lambda x: x.lower())\n",
    "test_df['treated_question'] = test_df['treated_question'].apply(lambda x: clean_contractions(x))\n",
    "test_df['treated_question'] = test_df['treated_question'].apply(lambda x: clean_special_chars(x))\n",
    "test_df['treated_question'] = test_df['treated_question'].apply(lambda x: correct_spelling(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ab9fc29433d90e5d99d5fe728bb92d3c613a1e9f",
    "colab_type": "text",
    "id": "QIn-67cmvDFk"
   },
   "source": [
    "## Fill data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "_uuid": "c3eff454f10f0f7ca9552205a993b094fa5b5c57",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "bbmOu7FPvNgI",
    "outputId": "653bd496-0185-474a-d557-9d3d2dbacf08"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1306122 training questions.\n",
      "Found 56370 test questions.\n"
     ]
    }
   ],
   "source": [
    "X_train = train_df['treated_question'].fillna('+++').tolist()\n",
    "y_train = train_df['target']\n",
    "X_test = test_df['treated_question'].fillna('+++').tolist()\n",
    "\n",
    "\n",
    "print('Found %s training questions.' % len(X_train))\n",
    "print('Found %s test questions.' % len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "_uuid": "d9bb5e7c69abf941c142775505c87fb8804f6345",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "_kbWqXCezaBA",
    "outputId": "79004f92-5f67-4ceb-caf0-01a78506cb9f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (1306122, 100)\n",
      "Shape of y_train: (1306122,)\n",
      "Found 195975 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "tokenizer = Tokenizer(num_words=MAX_WORDS, lower=True, split=' ', filters='',\n",
    "                       char_level=False, oov_token=None, document_count=0,\n",
    "                      )\n",
    "                                   \n",
    "tokenizer.fit_on_texts(X_train)\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_train = pad_sequences(X_train, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "X_test = tokenizer.texts_to_sequences(X_test)\n",
    "X_test = pad_sequences(X_test, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "print('Shape of X_train:', X_train.shape)\n",
    "print('Shape of y_train:', y_train.shape)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "print('Found %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "aedafbcf978e9c8eb2db0fa3fc650762f02d87a0",
    "colab_type": "text",
    "id": "BUSd8dmWEUf4"
   },
   "source": [
    "## Save tokenized data + word index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 248 ms, sys: 584 ms, total: 832 ms\n",
      "Wall time: 2.66 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import gc\n",
    "import pickle\n",
    "\n",
    "test_df.to_pickle('test_df.pkl')\n",
    "\n",
    "np.save('X_train.npy', X_train)\n",
    "np.save('X_test.npy', X_test)\n",
    "y_train.to_pickle('y_train.pkl')\n",
    "\n",
    "pickle.dump(word_index, open('word_index.pkl', 'wb'))\n",
    "\n",
    "del X_train\n",
    "del X_test\n",
    "del y_train\n",
    "\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "aedafbcf978e9c8eb2db0fa3fc650762f02d87a0",
    "colab_type": "text",
    "id": "BUSd8dmWEUf4"
   },
   "source": [
    "## Build vocabulary with counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "_uuid": "860e94814f74b4282fce01a2c8c42d7c29d1dabf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.8 s, sys: 404 ms, total: 13.2 s\n",
      "Wall time: 13.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "train_vocab = build_vocab(train_df['treated_question'])\n",
    "del train_df\n",
    "test_vocab = build_vocab(test_df['treated_question'])\n",
    "del test_df\n",
    "\n",
    "vocab = train_vocab + test_vocab\n",
    "del train_vocab\n",
    "del test_vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e1d40498bd469f8c5784570ddb88bb65a6367064",
    "colab_type": "text",
    "id": "BUSd8dmWEUf4"
   },
   "source": [
    "## Load embeddings, measure coverage and save embedding matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aNd1KcNjsvxj"
   },
   "source": [
    "# Restore point (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n%%time\\n\\nimport pickle\\n\\nword_index = pickle.load(open('word_index.pkl', 'rb'))\\n\""
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "%%time\n",
    "\n",
    "import pickle\n",
    "\n",
    "word_index = pickle.load(open('word_index.pkl', 'rb'))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "_uuid": "2801e906d9eb5bc96c231cf1e3d577a160d8d289",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "YfAhNjEJEXmN",
    "outputId": "58618a30-4fab-44f0-8dec-591a8df2da47"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glove:\n",
      "Loading embeddings from: ../input/embeddings/glove.840B.300d/glove.840B.300d.txt\n",
      "Found 2195892 word vectors.\n",
      "Found embeddings for 63.10% of vocab\n",
      "Found embeddings for  99.39% of all text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:2: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 49s, sys: 7.98 s, total: 2min 57s\n",
      "Wall time: 2min 52s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import gc\n",
    "\n",
    "print('glove:')\n",
    "glove_path = '../input/embeddings/glove.840B.300d/glove.840B.300d.txt'\n",
    "embeddings_index = loadEmbeddings(glove_path, EMBEDDING_DIM)\n",
    "check_coverage(vocab, embeddings_index)\n",
    "embedding_matrix = getEmbeddingMatrix(embeddings_index, word_index)\n",
    "del embeddings_index\n",
    "gc.collect()\n",
    "np.save('glove.npy', embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "_uuid": "889bc1ae4af9fe032c72e8c8c606ae5b1d66f7d8",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "YfAhNjEJEXmN",
    "outputId": "58618a30-4fab-44f0-8dec-591a8df2da47"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "paragram:\n",
      "Loading embeddings from: ../input/embeddings/paragram_300_sl999/paragram_300_sl999.txt\n",
      "Found 1703663 word vectors.\n",
      "Found embeddings for 74.06% of vocab\n",
      "Found embeddings for  99.64% of all text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:2: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "print('paragram:')\n",
    "paragram_path = '../input/embeddings/paragram_300_sl999/paragram_300_sl999.txt'\n",
    "embeddings_index = loadEmbeddings(paragram_path, EMBEDDING_DIM, encoding='utf8', errors='ignore')\n",
    "check_coverage(vocab, embeddings_index)\n",
    "embedding_matrix = getEmbeddingMatrix(embeddings_index, word_index)\n",
    "del embeddings_index\n",
    "gc.collect()\n",
    "np.save('paragram.npy', embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "_uuid": "79b0a76992718f29aec733bec9f59beb85302a31",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "YfAhNjEJEXmN",
    "outputId": "58618a30-4fab-44f0-8dec-591a8df2da47"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wiki:\n",
      "Loading embeddings from: ../input/embeddings/wiki-news-300d-1M/wiki-news-300d-1M.vec\n",
      "Found 999994 word vectors.\n",
      "Found embeddings for 48.05% of vocab\n",
      "Found embeddings for  98.81% of all text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:2: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "print('wiki:')\n",
    "wiki_path = '../input/embeddings/wiki-news-300d-1M/wiki-news-300d-1M.vec'\n",
    "embeddings_index = loadEmbeddings(wiki_path, EMBEDDING_DIM)\n",
    "check_coverage(vocab, embeddings_index)\n",
    "embedding_matrix = getEmbeddingMatrix(embeddings_index, word_index)\n",
    "del embeddings_index\n",
    "gc.collect()\n",
    "np.save('wiki.npy', embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "_uuid": "c1ec208ac42fbf73e8213442f1333cbf18791a16"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "google_news:\n",
      "Loading embeddings from: ../input/embeddings/GoogleNews-vectors-negative300/GoogleNews-vectors-negative300.bin\n",
      "Found 3000000 word vectors.\n",
      "Found embeddings for 38.68% of vocab\n",
      "Found embeddings for  78.84% of all text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:2: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "print('google_news:')\n",
    "google_news_path = '../input/embeddings/GoogleNews-vectors-negative300/GoogleNews-vectors-negative300.bin'\n",
    "embeddings_index = loadEmbeddingsGensim(google_news_path, EMBEDDING_DIM)\n",
    "check_coverage(vocab, embeddings_index)\n",
    "embedding_matrix = getEmbeddingMatrix(embeddings_index, word_index)\n",
    "del embeddings_index\n",
    "gc.collect()\n",
    "np.save('google_news.npy', embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "_uuid": "7711de071093e6c256b2e8bf68fe64e9436ba0e2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del word_index\n",
    "del vocab\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "380e34c9a8b4a797b10cb54e15760a9dd7b28ae0",
    "colab_type": "text",
    "id": "BUSd8dmWEUf4"
   },
   "source": [
    "# Oversample training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "_uuid": "47c26457a2b8c17015bf5c5c60cbb562fe199429"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom imblearn.over_sampling import SMOTE\\n\\nsm = SMOTE(random_state=42, ratio = 1.0)\\nX_train, y_train = sm.fit_sample(X_train, y_train)\\n'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "sm = SMOTE(random_state=42, ratio = 1.0)\n",
    "X_train, y_train = sm.fit_sample(X_train, y_train)\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "_uuid": "f28b53680bc8874337b09a61887d6c74da683659"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nbalanced_train_df = pd.DataFrame()\\nbalanced_train_df[0] = np.array(y_train)\\n\\ntarget_ratios = balanced_train_df[0].value_counts(normalize=True)\\n\\nprint(target_ratios)\\n\\ntarget_ratios.plot(kind='bar', title='Ratios after SMOTE (target)')\\n\""
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "balanced_train_df = pd.DataFrame()\n",
    "balanced_train_df[0] = np.array(y_train)\n",
    "\n",
    "target_ratios = balanced_train_df[0].value_counts(normalize=True)\n",
    "\n",
    "print(target_ratios)\n",
    "\n",
    "target_ratios.plot(kind='bar', title='Ratios after SMOTE (target)')\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "fab17b9cec7b6c69d9b96bfc5731882a1216d788",
    "colab_type": "text",
    "id": "aNd1KcNjsvxj"
   },
   "source": [
    "# Setup model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aNd1KcNjsvxj"
   },
   "source": [
    "# Restore point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 44 ms, sys: 320 ms, total: 364 ms\n",
      "Wall time: 2.19 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "test_df = pd.read_pickle('test_df.pkl')\n",
    "\n",
    "X_train = np.load('X_train.npy')\n",
    "X_test = np.load('X_test.npy')\n",
    "y_train = pd.read_pickle('y_train.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d45a12e7532c1ff87d68b626baada8a5bbe6b0fe",
    "colab_type": "text",
    "id": "BUSd8dmWEUf4"
   },
   "source": [
    "## Embeddings Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "_uuid": "48576619ba4f1847df5ea12bdd11b24b3920b25d"
   },
   "outputs": [],
   "source": [
    "from keras.layers import Embedding\n",
    "\n",
    "embedding_layers = {}\n",
    "\n",
    "embedding_matrix = np.load('glove.npy')\n",
    "embedding_layers['glove'] = Embedding(MAX_WORDS, EMBEDDING_DIM, weights=[embedding_matrix], input_length=MAX_SEQUENCE_LENGTH, trainable=True)\n",
    "\n",
    "embedding_matrix = np.load('paragram.npy')\n",
    "embedding_layers['paragram'] = Embedding(MAX_WORDS, EMBEDDING_DIM, weights=[embedding_matrix], input_length=MAX_SEQUENCE_LENGTH, trainable=True)\n",
    "\n",
    "embedding_matrix = np.load('wiki.npy')\n",
    "embedding_layers['wiki'] = Embedding(MAX_WORDS, EMBEDDING_DIM, weights=[embedding_matrix], input_length=MAX_SEQUENCE_LENGTH, trainable=True)\n",
    "\n",
    "embedding_matrix = np.load('google_news.npy')\n",
    "embedding_layers['google_news'] = Embedding(MAX_WORDS, EMBEDDING_DIM, weights=[embedding_matrix], input_length=MAX_SEQUENCE_LENGTH, trainable=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "60a8b6ecb457fff127b4f7db954c42c63fa68b76",
    "colab_type": "text",
    "id": "BUSd8dmWEUf4"
   },
   "source": [
    "## NN: Bidirectional GRU per embedding with concactenation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "_uuid": "2d9a7a2733cee240d25312c05c08d41e0d6c4976"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 100)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 100, 300)     15000000    input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 100, 300)     15000000    input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, 100, 300)     15000000    input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_4 (Embedding)         (None, 100, 300)     15000000    input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 100, 128)     140544      embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) (None, 100, 128)     140544      embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_3 (Bidirectional) (None, 100, 128)     140544      embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_4 (Bidirectional) (None, 100, 128)     140544      embedding_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 100, 128)     512         bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 100, 128)     512         bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 100, 128)     512         bidirectional_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 100, 128)     512         bidirectional_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_1 (GlobalM (None, 128)          0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_2 (GlobalM (None, 128)          0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_3 (GlobalM (None, 128)          0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_4 (GlobalM (None, 128)          0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 16)           2048        global_max_pooling1d_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 16)           2048        global_max_pooling1d_2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 16)           2048        global_max_pooling1d_3[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 16)           2048        global_max_pooling1d_4[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 16)           64          dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 16)           64          dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 16)           64          dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 16)           64          dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 16)           0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 16)           0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 16)           0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 16)           0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 16)           0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 16)           0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 16)           0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 16)           0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 64)           0           dropout_1[0][0]                  \n",
      "                                                                 dropout_2[0][0]                  \n",
      "                                                                 dropout_3[0][0]                  \n",
      "                                                                 dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 32)           2048        concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 32)           128         dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 32)           0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 1)            32          activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 1)            4           dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 1)            0           batch_normalization_10[0][0]     \n",
      "==================================================================================================\n",
      "Total params: 60,574,884\n",
      "Trainable params: 60,573,666\n",
      "Non-trainable params: 1,218\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "CPU times: user 10.5 s, sys: 2.7 s, total: 13.2 s\n",
      "Wall time: 11.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "from keras.layers import Dense, Dropout, Input, GlobalMaxPool1D\n",
    "from keras.layers import Conv1D, MaxPooling1D, Embedding, Bidirectional\n",
    "from keras.layers import Activation, BatchNormalization, CuDNNGRU\n",
    "from keras.layers import SpatialDropout1D, Concatenate, Flatten, Reshape\n",
    "from keras.regularizers import l2\n",
    "from keras.models import Model\n",
    "\n",
    "\n",
    "inp = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "\n",
    "a = embedding_layers['glove'] (inp)\n",
    "a = Bidirectional(CuDNNGRU(64, return_sequences=True))(a)\n",
    "a = BatchNormalization()(a)\n",
    "a = GlobalMaxPool1D()(a)\n",
    "a = Dense(16, kernel_regularizer=l2(0.01), use_bias=False)(a)\n",
    "a = BatchNormalization()(a)\n",
    "a = Activation(\"relu\")(a)\n",
    "a = Dropout(0.1)(a)\n",
    "\n",
    "b = embedding_layers['paragram'] (inp)\n",
    "b = Bidirectional(CuDNNGRU(64, return_sequences=True))(b)\n",
    "b = BatchNormalization()(b)\n",
    "b = GlobalMaxPool1D()(b)\n",
    "b = Dense(16, kernel_regularizer=l2(0.01), use_bias=False)(b)\n",
    "b = BatchNormalization()(b)\n",
    "b = Activation(\"relu\")(b)\n",
    "b = Dropout(0.1)(b)\n",
    "\n",
    "c = embedding_layers['wiki'] (inp)\n",
    "c = Bidirectional(CuDNNGRU(64, return_sequences=True))(c)\n",
    "c = BatchNormalization()(c)\n",
    "c = GlobalMaxPool1D()(c)\n",
    "c = Dense(16, kernel_regularizer=l2(0.01), use_bias=False)(c)\n",
    "c = BatchNormalization()(c)\n",
    "c = Activation(\"relu\")(c)\n",
    "c = Dropout(0.1)(c)\n",
    "\n",
    "d = embedding_layers['google_news'] (inp)\n",
    "d = Bidirectional(CuDNNGRU(64, return_sequences=True))(d)\n",
    "d = BatchNormalization()(d)\n",
    "d = GlobalMaxPool1D()(d)\n",
    "d = Dense(16, kernel_regularizer=l2(0.01), use_bias=False)(d)\n",
    "d = BatchNormalization()(d)\n",
    "d = Activation(\"relu\")(d)\n",
    "d = Dropout(0.1)(d)\n",
    "\n",
    "x = Concatenate(axis=1)([a, b, c, d])\n",
    "x = Dense(32, kernel_regularizer=l2(0.01), use_bias=False)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation(\"relu\")(x)\n",
    "x = Dense(1, use_bias=False)(x)\n",
    "x = BatchNormalization()(x)\n",
    "out = Activation(\"sigmoid\")(x)\n",
    "\n",
    "model = Model(inp, out)\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    " \n",
    "def f1(y_true, y_pred):\n",
    "    p = precision(y_true, y_pred)\n",
    "    r = recall(y_true, y_pred)\n",
    "    return 2*((p*r)/(p+r+K.epsilon()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "74e7edd06d9d1ef89f4369021b8ce094be9e21db",
    "colab_type": "text",
    "id": "Lp4o2h9Fs8gP"
   },
   "source": [
    "# Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "_uuid": "fafbbea8029e31d17a3f731639bbc62970e4e1b0",
    "colab": {},
    "colab_type": "code",
    "id": "L75Rc0Gqtclm"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy', f1, recall, precision])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NVFKqCPUtJcy"
   },
   "source": [
    "# serialize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "model.save('model.h5')\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aNd1KcNjsvxj"
   },
   "source": [
    "# Setup f1-score, precision and recall metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "checkpoints = ModelCheckpoint(MODEL_VERSION + '.weights_checkpoint.h5', monitor=\"val_f1\", mode=\"max\", verbose=True, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom keras.callbacks import Callback\\nfrom sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score, precision_recall_fscore_support\\n\\nclass Metrics(Callback):\\n\\n\\n    def on_train_begin(self, logs={}):\\n        self.val_f1s = []\\n        self.val_recalls = []\\n        self.val_precisions = []\\n \\n\\n    def on_epoch_end(self, epoch, logs={}):\\n        val_predict = (np.asarray(self.model.predict(self.validation_data[0]))).round()\\n        val_targ = self.validation_data[1]\\n        _val_precision, _val_recall, _val_f1, _ = precision_recall_fscore_support(val_targ, val_predict, average=\\'binary\\')\\n        self.val_f1s.append(_val_f1)\\n        self.val_recalls.append(_val_recall)\\n        self.val_precisions.append(_val_precision)\\n        print(\" — val_f1: %f — val_precision: %f — val_recall: %f\" %(_val_f1, _val_precision, _val_recall))\\n        return\\n\\nmetrics = Metrics()\\n'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from keras.callbacks import Callback\n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score, precision_recall_fscore_support\n",
    "\n",
    "class Metrics(Callback):\n",
    "\n",
    "\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.val_f1s = []\n",
    "        self.val_recalls = []\n",
    "        self.val_precisions = []\n",
    " \n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        val_predict = (np.asarray(self.model.predict(self.validation_data[0]))).round()\n",
    "        val_targ = self.validation_data[1]\n",
    "        _val_precision, _val_recall, _val_f1, _ = precision_recall_fscore_support(val_targ, val_predict, average='binary')\n",
    "        self.val_f1s.append(_val_f1)\n",
    "        self.val_recalls.append(_val_recall)\n",
    "        self.val_precisions.append(_val_precision)\n",
    "        print(\" — val_f1: %f — val_precision: %f — val_recall: %f\" %(_val_f1, _val_precision, _val_recall))\n",
    "        return\n",
    "\n",
    "metrics = Metrics()\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "21e24633c2528b71fc434bf528f7b29fbed63f25",
    "colab_type": "text",
    "id": "QIn-67cmvDFk"
   },
   "source": [
    "## Split train/validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "_uuid": "3a4e4292f236ac2a779968bb38239e61e5f48eab"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/.local/lib/python3.5/site-packages/sklearn/model_selection/_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, train_size=0.8,\n",
    "                                              random_state=233)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1d1c4d092bca6f093254b5792c4b8801c1282b0f",
    "colab_type": "text",
    "id": "NVFKqCPUtJcy"
   },
   "source": [
    "# Train the model\n",
    "\n",
    "Use model checkpointing to save the model that attains the best validation loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2db478168d542638ce5cb6358de7ebd503d000b0",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "3OwX8ErsteZL",
    "outputId": "f718108c-5f78-4d9b-8814-c7044a9cce96"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1044897 samples, validate on 261225 samples\n",
      "Epoch 1/2\n",
      "1044736/1044897 [============================>.] - ETA: 0s - loss: 0.3003 - acc: 0.9440 - f1: 0.6076 - recall: 0.6718 - precision: 0.5945"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "hist = model.fit(X_train, y_train, validation_data=(X_val, y_val), callbacks=[checkpoints], epochs=2, batch_size=256)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "926710a7b8364a65a6ea5bdb8f103462b622549c",
    "colab_type": "text",
    "id": "NVFKqCPUtJcy"
   },
   "source": [
    "# Predict validation labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "80dbd1aae9b5ec74071b7a11de96abee7cd2ad66"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "pred_val = model.predict([X_val], batch_size=1024, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "fbe1a9626a625a4540b35fe646af0d78e8952b24",
    "colab_type": "text",
    "id": "NVFKqCPUtJcy"
   },
   "source": [
    "# Find optimal threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c5861eb15765c20d4a5be5892543520bdb006bfa"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "\n",
    "def optimalThreshold(y_true,y_pred):\n",
    "    idx = 0\n",
    "    cur_f1 = 0\n",
    "    cur_prec = 0\n",
    "    cur_recall = 0\n",
    "    max_f1 = 0\n",
    "    thres = 0\n",
    "    for idx in np.arange(0.1, 0.501, 0.01):\n",
    "        cur_f1 = f1_score(y_true, np.array(y_pred)> idx)\n",
    "        cur_recall = recall_score(y_true, np.array(y_pred)> idx)\n",
    "        cur_prec = precision_score(y_true, np.array(y_pred)> idx)\n",
    "        print('Current threshold is {:.4f} with F1 score: {:.4f}, Recall score: {:.4f}, Precision score: {:.4f}'\n",
    "              .format(idx, cur_f1, cur_recall, cur_prec)\n",
    "             )\n",
    "        if cur_f1 > max_f1:\n",
    "            max_f1 = cur_f1\n",
    "            thres = idx\n",
    "    print('optimal threshold is {:.4f} with F1 score: {:.4f}'.format(thres, max_f1))\n",
    "    return thres\n",
    "threshold = optimalThreshold(y_val,pred_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "print(classification_report(y_val, np.array(pred_val > threshold).astype(int), target_names=['sincere', 'insincere']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "cm = confusion_matrix(y_val, np.array(pred_val > threshold).astype(int))\n",
    "ax = plt.subplot()\n",
    "hm = sns.heatmap(cm, annot=True, ax = ax, fmt='g', \n",
    "                 cmap=ListedColormap(['white']), linecolor='black', \n",
    "                 linewidth=1, cbar=False,\n",
    "                 xticklabels = 1, yticklabels = 1 )\n",
    "\n",
    "\n",
    "# labels, title and ticks\n",
    "ax.set_xlabel('Predicted labels')\n",
    "ax.set_ylabel('True labels') \n",
    "ax.set_title('Confusion Matrix')\n",
    "ax.xaxis.set_ticklabels(['sincere', 'insincere'])\n",
    "ax.yaxis.set_ticklabels(['sincere', 'insincere'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0ff585d4c11ae673051881795e74ff97d8d2b4c8"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "plt.title('model accuracy')\n",
    "plt.plot(hist.history['acc'])\n",
    "plt.plot(hist.history['val_acc'])\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0ff585d4c11ae673051881795e74ff97d8d2b4c8"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "plt.title('model loss')\n",
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0ff585d4c11ae673051881795e74ff97d8d2b4c8"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "plt.title('model F1-score')\n",
    "plt.plot(hist.history['f1'])\n",
    "plt.plot(hist.history['val_f1'])\n",
    "plt.ylabel('f1 score')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d377f47a86a67e1b60bf83efa2e85c08e87281dd",
    "colab_type": "text",
    "id": "NVFKqCPUtJcy"
   },
   "source": [
    "# Predict test labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0670f1a7c1ed5cfd85d049dfc0ef1681aaab055b"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "pred_test = model.predict([X_test], batch_size=1024, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f3c1ff0ac4324bbf847ed3fdafe4db682d833f8a",
    "colab_type": "text",
    "id": "NVFKqCPUtJcy"
   },
   "source": [
    "# Prepare submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7f3601299112b7d1ea815db80243344ace06ca42"
   },
   "outputs": [],
   "source": [
    "submission_df = pd.DataFrame({\"qid\":test_df[\"qid\"].values})\n",
    "submission_df['prediction'] = (pred_test > threshold).astype(int)\n",
    "submission_df.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "\n",
    "pickle_out = open(MODEL_VERSION + '.hist.pkl',\"wb\")\n",
    "pickle.dump(hist, pickle_out)\n",
    "pickle_out.close()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "capstone.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
