{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "85c12f788178232533cbf7f141e217c32b882cda",
    "colab_type": "text",
    "id": "w7oagxHHofxb"
   },
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_uuid": "f0421d98769ce1b3bcc0b65f729851be0d275cb5"
   },
   "outputs": [],
   "source": [
    "MAX_SEQUENCE_LENGTH = 250\n",
    "EMBEDDING_DIM = 300\n",
    "MAX_WORDS = 100000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "749cb0b7d343d12569698ece840039c7fef54711",
    "colab_type": "text",
    "id": "BUSd8dmWEUf4"
   },
   "source": [
    "## Common english contraction mappings (wikipedia):\n",
    "https://en.wikipedia.org/wiki/Wikipedia:List_of_English_contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "d5a645a8f6a9f70d9db108cebbc683089e548260"
   },
   "outputs": [],
   "source": [
    "CONTRACTION_MAPPING = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\", \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\", \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",  \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\", \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\", \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\", \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\", \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\", \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\", \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\", \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\", \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\", \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\", \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\", \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\", \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",  \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\", \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\", \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\", \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\", \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\", \"you're\": \"you are\", \"you've\": \"you have\" }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "56282f6e5433223f3823e24e95fe170534e8dcae"
   },
   "outputs": [],
   "source": [
    "PUNCT = \"/-'?!.,#$%\\'()*+-/:;<=>@[\\\\]^_`{|}~\" + '\"\"“”’' + '∞θ÷α•à−β∅³π‘₹´°£€\\×™√²—–&'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "a2a79c0d80f797d3868fac83217b1e2479bee8dc"
   },
   "outputs": [],
   "source": [
    "SPECIAL_PUNCT = {'\\u200b': ' ', '…': ' ... ', '\\ufeff': '', 'करना': '', 'है': ''}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "451df1dd80192c375340a023e852cab39698d434"
   },
   "outputs": [],
   "source": [
    "PUNCT_MAPPING = {\"‘\": \"'\", \"₹\": \"e\", \"´\": \"'\", \"°\": \"\", \"€\": \"e\", \"™\": \"tm\", \"√\": \" sqrt \", \"×\": \"x\", \"²\": \"2\", \"—\": \"-\", \"–\": \"-\", \"’\": \"'\", \"_\": \"-\", \"`\": \"'\", '“': '\"', '”': '\"', '“': '\"', \"£\": \"e\", '∞': 'infinity', 'θ': 'theta', '÷': '/', 'α': 'alpha', '•': '.', 'à': 'a', '−': '-', 'β': 'beta', '∅': '', '³': '3', 'π': 'pi', }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "228dc3ca14b0b0af33d6c874400d8f01ef96a874"
   },
   "outputs": [],
   "source": [
    "MISPELL_MAPPING = {'colour': 'color', 'centre': 'center', 'favourite': 'favorite', 'travelling': 'traveling', 'counselling': 'counseling', 'theatre': 'theater', 'cancelled': 'canceled', 'labour': 'labor', 'organisation': 'organization', 'wwii': 'world war 2', 'citicise': 'criticize', 'youtu ': 'youtube ', 'Qoura': 'Quora', 'sallary': 'salary', 'Whta': 'What', 'narcisist': 'narcissist', 'howdo': 'how do', 'whatare': 'what are', 'howcan': 'how can', 'howmuch': 'how much', 'howmany': 'how many', 'whydo': 'why do', 'doI': 'do I', 'theBest': 'the best', 'howdoes': 'how does', 'mastrubation': 'masturbation', 'mastrubate': 'masturbate', \"mastrubating\": 'masturbating', 'pennis': 'penis', 'Etherium': 'Ethereum', 'narcissit': 'narcissist', 'bigdata': 'big data', '2k17': '2017', '2k18': '2018', 'qouta': 'quota', 'exboyfriend': 'ex boyfriend', 'airhostess': 'air hostess', \"whst\": 'what', 'watsapp': 'whatsapp', 'demonitisation': 'demonetization', 'demonitization': 'demonetization', 'demonetisation': 'demonetization', 'pokémon': 'pokemon'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "974ca8fb2157648f2ace9c41bf37e0d87dd2eb20",
    "colab_type": "text",
    "id": "w7oagxHHofxb"
   },
   "source": [
    "# Helpers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "408f2ecb4a7380c2a57635996ca248020e4aaa94",
    "colab_type": "text",
    "id": "BUSd8dmWEUf4"
   },
   "source": [
    "## Embedding helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "88880adc1b1e2ca67e77db81d36165fad52d9e1c"
   },
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def loadEmbeddings(path, dimensions, mode='r', encoding=None, errors=None):\n",
    "    print('Loading embeddings from: %s' %path)\n",
    "    embeddings = {}\n",
    "    f = open(path, buffering=((2<<16) + 8), mode=mode, encoding=encoding, errors=errors)\n",
    "    for line in f:\n",
    "        if len(line) <= 100:\n",
    "            continue\n",
    "        values = line.split()\n",
    "        word = ''.join(values[:-dimensions])\n",
    "        coefs = np.asarray(values[-dimensions:], dtype='float32')\n",
    "        embeddings[word] = coefs\n",
    "    f.close()\n",
    "    print('Found %s word vectors.' % len(embeddings))\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "1f202cf2766c8d2a73834f057bd195928136ce1b"
   },
   "outputs": [],
   "source": [
    "def loadEmbeddingsGensim(path, dimensions, binary=True):\n",
    "    print('Loading embeddings from: %s' %path)\n",
    "    embeddings = {}\n",
    "    gensim_vecs = KeyedVectors.load_word2vec_format(path, binary=binary)\n",
    "    for word, vector in zip(gensim_vecs.vocab, gensim_vecs.vectors):\n",
    "        coefs = np.asarray(vector[-dimensions:], dtype='float32')\n",
    "        embeddings[word] = coefs\n",
    "    print('Found %s word vectors.' % len(embeddings))\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "344bdbebf5757946836407ee4a0a8ace39b65228",
    "colab": {},
    "colab_type": "code",
    "id": "0KeJJofUpQm9"
   },
   "outputs": [],
   "source": [
    "def getEmbeddingMatrix(embedding, word_index):\n",
    "    all_embs = np.stack(embedding.values())\n",
    "    emb_mean,emb_std = all_embs.mean(), all_embs.std()\n",
    "    embed_size = all_embs.shape[1]\n",
    "    \n",
    "    nb_words = min(MAX_WORDS, len(word_index))\n",
    "    embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embed_size))\n",
    "    for word, i in word_index.items():\n",
    "        if i >= MAX_WORDS:\n",
    "            continue\n",
    "        embedding_vector = embedding.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "    \n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e462ed6a5cd6b481db42664c68c3451b61026d76",
    "colab_type": "text",
    "id": "BUSd8dmWEUf4"
   },
   "source": [
    "### Helper to replace contractions in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "e9cd4f331303cea868030ed771c30c01a65f74a7"
   },
   "outputs": [],
   "source": [
    "def clean_contractions(text):\n",
    "    specials = [\"’\", \"‘\", \"´\", \"`\"]\n",
    "    for s in specials:\n",
    "        text = text.replace(s, \"'\")\n",
    "    text = ' '.join([CONTRACTION_MAPPING[t] if t in CONTRACTION_MAPPING else t for t in text.split(\" \")])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4d9fd63b54dda11ec562c8e2c85fa386e9910958",
    "colab_type": "text",
    "id": "BUSd8dmWEUf4"
   },
   "source": [
    "### Helper to remap punctuations in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "c1b038b3cadf6c09fcb2523a1171ad8e95a1700d"
   },
   "outputs": [],
   "source": [
    "def clean_special_chars(text):\n",
    "    for p in PUNCT_MAPPING:\n",
    "        text = text.replace(p, PUNCT_MAPPING[p])\n",
    "    \n",
    "    for p in PUNCT:\n",
    "        text = text.replace(p, ' ' + p + ' ')\n",
    "    \n",
    "    for s in SPECIAL_PUNCT:\n",
    "        text = text.replace(s, SPECIAL_PUNCT[s])\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "dbcf585e91cd7faad3c230d6eb191dc39695db17",
    "colab_type": "text",
    "id": "BUSd8dmWEUf4"
   },
   "source": [
    "### Helper to correct common mispellings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "186bf0c75630a56d02120c197712e4fb5681ad8d"
   },
   "outputs": [],
   "source": [
    "def correct_spelling(x):\n",
    "    for word in MISPELL_MAPPING.keys():\n",
    "        x = x.replace(word, MISPELL_MAPPING[word])\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "92cc1a4a5777c338f819adde4ec455d9856013dc",
    "colab_type": "text",
    "id": "BUSd8dmWEUf4"
   },
   "source": [
    "## Coverage helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "20732a275083041d5a06ad4bd6a7938f7333afda"
   },
   "outputs": [],
   "source": [
    "def build_vocab(texts):\n",
    "    sentences = texts.apply(lambda x: x.split()).values\n",
    "    vocab = {}\n",
    "    for sentence in sentences:\n",
    "        for word in sentence:\n",
    "            try:\n",
    "                vocab[word] += 1\n",
    "            except KeyError:\n",
    "                vocab[word] = 1\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "b83aab607f791f5824b3eca4277741950cd36d92"
   },
   "outputs": [],
   "source": [
    "import operator\n",
    "\n",
    "def check_coverage(vocab, embeddings_index):\n",
    "    known_words = {}\n",
    "    unknown_words = {}\n",
    "    nb_known_words = 0\n",
    "    nb_unknown_words = 0\n",
    "    for word in vocab.keys():\n",
    "        try:\n",
    "            known_words[word] = embeddings_index[word]\n",
    "            nb_known_words += vocab[word]\n",
    "        except:\n",
    "            unknown_words[word] = vocab[word]\n",
    "            nb_unknown_words += vocab[word]\n",
    "            pass\n",
    "\n",
    "    print('Found embeddings for {:.2%} of vocab'.format(len(known_words) / len(vocab)))\n",
    "    print('Found embeddings for  {:.2%} of all text'.format(nb_known_words / (nb_known_words + nb_unknown_words)))\n",
    "    unknown_words = sorted(unknown_words.items(), key=operator.itemgetter(1))[::-1]\n",
    "\n",
    "    return unknown_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "70e187637082e5f448863c5f965fff8ab80ed065",
    "colab_type": "text",
    "id": "w7oagxHHofxb"
   },
   "source": [
    "# Import test/train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "e20e43f9ea433ee2eee88003355ef86f724fa01c",
    "colab": {},
    "colab_type": "code",
    "id": "X3n8bRW6WcKo"
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"../input/train.csv\")\n",
    "test_df = pd.read_csv(\"../input/test.csv\")\n",
    "\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.max_rows = None\n",
    "pd.options.display.max_colwidth = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2052ad18f26ea6c28d4feeaac402d61438a6f1cf",
    "colab_type": "text",
    "id": "w7oagxHHofxb"
   },
   "source": [
    "# Analyze train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_uuid": "8f55a111d1222a541a6cc5938de12577b3b12215",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 393
    },
    "colab_type": "code",
    "id": "h0aRi6Toaq8j",
    "outputId": "5d5c6246-c8c3-49e0-e8b7-58850a83f62f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample insincere questions\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>question_text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>506825</th>\n",
       "      <td>633ca3709f7705288ac3</td>\n",
       "      <td>Why are European-Americans so argumentative, especially towards black people? No matter what question we ask we get attacked?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1199708</th>\n",
       "      <td>eb22cf25df2523c76ad8</td>\n",
       "      <td>Did you guys hear about Trump launching missiles at Russia and Syria?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>609811</th>\n",
       "      <td>776a111643f041ef66ee</td>\n",
       "      <td>Why are Pakistanis obsessed with Iran and Iranian people?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399700</th>\n",
       "      <td>4e4edf66de48b44613c3</td>\n",
       "      <td>Why is it that when an Christian tells you that you are doomed to rot in hell for being a stupid arrogant heretic it's ok but when an atheist questions the irrationality of their beliefs they are called \"disrespectful\", \"aggressive\" and such?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>792185</th>\n",
       "      <td>9b39e3cc9dc0623a359a</td>\n",
       "      <td>Why do Ayurvedic doctos hype so much about Ayurveda though it is not true in reality?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560831</th>\n",
       "      <td>6dddd8810f5cbec3f3d2</td>\n",
       "      <td>Why is left wing violence given a pass in the news?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478108</th>\n",
       "      <td>5d9f3bf33afd5af4c1c1</td>\n",
       "      <td>Does our government cover up evidence of God, like it does the remains of giants found all over the world?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89506</th>\n",
       "      <td>118aa979738056a26aef</td>\n",
       "      <td>How can people celebrate Emma Gonzalez after she publicly ripped up the Constitution?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>827288</th>\n",
       "      <td>a220cb0523ada5763d54</td>\n",
       "      <td>Why are white women pretending racism was only the white men fault?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29642</th>\n",
       "      <td>05cc69301509a5fafa96</td>\n",
       "      <td>Why are drivers so stupid?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          qid  \\\n",
       "506825   633ca3709f7705288ac3   \n",
       "1199708  eb22cf25df2523c76ad8   \n",
       "609811   776a111643f041ef66ee   \n",
       "399700   4e4edf66de48b44613c3   \n",
       "792185   9b39e3cc9dc0623a359a   \n",
       "560831   6dddd8810f5cbec3f3d2   \n",
       "478108   5d9f3bf33afd5af4c1c1   \n",
       "89506    118aa979738056a26aef   \n",
       "827288   a220cb0523ada5763d54   \n",
       "29642    05cc69301509a5fafa96   \n",
       "\n",
       "                                                                                                                                                                                                                                              question_text  \\\n",
       "506825   Why are European-Americans so argumentative, especially towards black people? No matter what question we ask we get attacked?                                                                                                                        \n",
       "1199708  Did you guys hear about Trump launching missiles at Russia and Syria?                                                                                                                                                                                \n",
       "609811   Why are Pakistanis obsessed with Iran and Iranian people?                                                                                                                                                                                            \n",
       "399700   Why is it that when an Christian tells you that you are doomed to rot in hell for being a stupid arrogant heretic it's ok but when an atheist questions the irrationality of their beliefs they are called \"disrespectful\", \"aggressive\" and such?   \n",
       "792185   Why do Ayurvedic doctos hype so much about Ayurveda though it is not true in reality?                                                                                                                                                                \n",
       "560831   Why is left wing violence given a pass in the news?                                                                                                                                                                                                  \n",
       "478108   Does our government cover up evidence of God, like it does the remains of giants found all over the world?                                                                                                                                           \n",
       "89506    How can people celebrate Emma Gonzalez after she publicly ripped up the Constitution?                                                                                                                                                                \n",
       "827288   Why are white women pretending racism was only the white men fault?                                                                                                                                                                                  \n",
       "29642    Why are drivers so stupid?                                                                                                                                                                                                                           \n",
       "\n",
       "         target  \n",
       "506825   1       \n",
       "1199708  1       \n",
       "609811   1       \n",
       "399700   1       \n",
       "792185   1       \n",
       "560831   1       \n",
       "478108   1       \n",
       "89506    1       \n",
       "827288   1       \n",
       "29642    1       "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Sample insincere questions\")\n",
    "train_df.loc[train_df['target'] == 1].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_uuid": "73bd9f42266c6c2184ff65017ccb5f62e38314f5",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 376
    },
    "colab_type": "code",
    "id": "n_mslOIdaj8G",
    "outputId": "c0c9da0b-96d8-436f-fe37-28a2da1d6b69"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample sincere questions\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>question_text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>711329</th>\n",
       "      <td>8b415fe58fe211e08fa0</td>\n",
       "      <td>What is justice to you when no one is looking?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11925</th>\n",
       "      <td>02580a7411b06fca24ef</td>\n",
       "      <td>Which selective chapter should I study to score 100 marks in Jee Advanced? Pls mention only topics.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1264265</th>\n",
       "      <td>f7c36091c1d0d4f34c51</td>\n",
       "      <td>What are the best creams for breast tighten?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>969540</th>\n",
       "      <td>bdf796e6f404ceb86da7</td>\n",
       "      <td>What does mpv means?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333451</th>\n",
       "      <td>415acf94c45737d57011</td>\n",
       "      <td>What happend when acetonitril undergoes acid hydrolysis?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234206</th>\n",
       "      <td>2dced7b2a9adfd755fb5</td>\n",
       "      <td>Why are literacy tests have been administered by various governments to immigrants?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477919</th>\n",
       "      <td>5d95a0b6f7213391b1ad</td>\n",
       "      <td>How do I know if a girl I just started being friends with loves me or not?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>762944</th>\n",
       "      <td>95792ab2e5743961f1c7</td>\n",
       "      <td>How is living in London?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>932394</th>\n",
       "      <td>b6b8ed07df188c1cd4fa</td>\n",
       "      <td>What do you think could be the main cause or contribution to cultural blasphemy in African countries?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>631821</th>\n",
       "      <td>7bba80e90ea53e3ed5fd</td>\n",
       "      <td>Why does black symbolize power?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          qid  \\\n",
       "711329   8b415fe58fe211e08fa0   \n",
       "11925    02580a7411b06fca24ef   \n",
       "1264265  f7c36091c1d0d4f34c51   \n",
       "969540   bdf796e6f404ceb86da7   \n",
       "333451   415acf94c45737d57011   \n",
       "234206   2dced7b2a9adfd755fb5   \n",
       "477919   5d95a0b6f7213391b1ad   \n",
       "762944   95792ab2e5743961f1c7   \n",
       "932394   b6b8ed07df188c1cd4fa   \n",
       "631821   7bba80e90ea53e3ed5fd   \n",
       "\n",
       "                                                                                                 question_text  \\\n",
       "711329   What is justice to you when no one is looking?                                                          \n",
       "11925    Which selective chapter should I study to score 100 marks in Jee Advanced? Pls mention only topics.     \n",
       "1264265  What are the best creams for breast tighten?                                                            \n",
       "969540   What does mpv means?                                                                                    \n",
       "333451   What happend when acetonitril undergoes acid hydrolysis?                                                \n",
       "234206   Why are literacy tests have been administered by various governments to immigrants?                     \n",
       "477919   How do I know if a girl I just started being friends with loves me or not?                              \n",
       "762944   How is living in London?                                                                                \n",
       "932394   What do you think could be the main cause or contribution to cultural blasphemy in African countries?   \n",
       "631821   Why does black symbolize power?                                                                         \n",
       "\n",
       "         target  \n",
       "711329   0       \n",
       "11925    0       \n",
       "1264265  0       \n",
       "969540   0       \n",
       "333451   0       \n",
       "234206   0       \n",
       "477919   0       \n",
       "762944   0       \n",
       "932394   0       \n",
       "631821   0       "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Sample sincere questions\")\n",
    "train_df.loc[train_df['target'] == 0].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_uuid": "7b8a948c3ae97a09decf8f0a6fadff9eed5f83b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.93813\n",
      "1    0.06187\n",
      "Name: target, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fbb0056ae10>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "target_ratios = train_df.target.value_counts(normalize=True)\n",
    "\n",
    "print(target_ratios)\n",
    "\n",
    "target_ratios.plot(kind='bar', title='Ratios (target)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_uuid": "323d3c4ed532d94120a8681d822c5ad60fc6abae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average word length of questions in train is 13.\n",
      "Average word length of questions in test is 13.\n"
     ]
    }
   ],
   "source": [
    "print('Average word length of questions in train is {0:.0f}.'.format(np.mean(train_df['question_text'].apply(lambda x: len(x.split())))))\n",
    "print('Average word length of questions in test is {0:.0f}.'.format(np.mean(test_df['question_text'].apply(lambda x: len(x.split())))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_uuid": "3b49c4e9bbe8ab8ccddfc8b9c8b24bcafe1bbd3c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max word length of questions in train is 134.\n",
      "Max word length of questions in test is 87.\n"
     ]
    }
   ],
   "source": [
    "print('Max word length of questions in train is {0:.0f}.'.format(np.max(train_df['question_text'].apply(lambda x: len(x.split())))))\n",
    "print('Max word length of questions in test is {0:.0f}.'.format(np.max(test_df['question_text'].apply(lambda x: len(x.split())))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_uuid": "83ede400076de1e67b90de70553ae273d0b16473"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average character length of questions in train is 71.\n",
      "Average character length of questions in test is 70.\n"
     ]
    }
   ],
   "source": [
    "print('Average character length of questions in train is {0:.0f}.'.format(np.mean(train_df['question_text'].apply(lambda x: len(x)))))\n",
    "print('Average character length of questions in test is {0:.0f}.'.format(np.mean(test_df['question_text'].apply(lambda x: len(x)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_uuid": "1b66752d7dfea96b9c5b171edfe6f6d2831956a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max character length of questions in train is 1017.\n",
      "Max character length of questions in test is 588.\n"
     ]
    }
   ],
   "source": [
    "print('Max character length of questions in train is {0:.0f}.'.format(np.max(train_df['question_text'].apply(lambda x: len(x)))))\n",
    "print('Max character length of questions in test is {0:.0f}.'.format(np.max(test_df['question_text'].apply(lambda x: len(x)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_uuid": "5ff56f79415f02f3a029a2a12c40444410427763"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p999 character length of questions in train is 249.\n",
      "p999 character length of questions in test is 249.\n"
     ]
    }
   ],
   "source": [
    "print('p999 character length of questions in train is {0:.0f}.'.format(np.percentile(train_df['question_text'].apply(lambda x: len(x)), 99.9)))\n",
    "print('p999 character length of questions in test is {0:.0f}.'.format(np.percentile(test_df['question_text'].apply(lambda x: len(x)), 99.9)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "755dc21b8d2ad16d4711e5f3cfc664617fba4a3f",
    "colab_type": "text",
    "id": "QIn-67cmvDFk"
   },
   "source": [
    "# Data processing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e32a7c365a4f71149537c44eca72b762c0cf1a8b",
    "colab_type": "text",
    "id": "QIn-67cmvDFk"
   },
   "source": [
    "## TODO: Feature engineering\n",
    "\n",
    "Add feature engineering here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "_uuid": "a65029f02944902ad1c4a3b988ba4d166ce26910"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 52 s, sys: 340 ms, total: 52.3 s\n",
      "Wall time: 52.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "train_df['treated_question'] = train_df['question_text'].apply(lambda x: x.lower())\n",
    "train_df['treated_question'] = train_df['treated_question'].apply(lambda x: clean_contractions(x))\n",
    "train_df['treated_question'] = train_df['treated_question'].apply(lambda x: clean_special_chars(x))\n",
    "train_df['treated_question'] = train_df['treated_question'].apply(lambda x: correct_spelling(x))\n",
    "\n",
    "test_df['treated_question'] = test_df['question_text'].apply(lambda x: x.lower())\n",
    "test_df['treated_question'] = test_df['treated_question'].apply(lambda x: clean_contractions(x))\n",
    "test_df['treated_question'] = test_df['treated_question'].apply(lambda x: clean_special_chars(x))\n",
    "test_df['treated_question'] = test_df['treated_question'].apply(lambda x: correct_spelling(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "21e24633c2528b71fc434bf528f7b29fbed63f25",
    "colab_type": "text",
    "id": "QIn-67cmvDFk"
   },
   "source": [
    "## Split train/validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "_uuid": "3a4e4292f236ac2a779968bb38239e61e5f48eab"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ab9fc29433d90e5d99d5fe728bb92d3c613a1e9f",
    "colab_type": "text",
    "id": "QIn-67cmvDFk"
   },
   "source": [
    "## Fill data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "_uuid": "c3eff454f10f0f7ca9552205a993b094fa5b5c57",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "bbmOu7FPvNgI",
    "outputId": "653bd496-0185-474a-d557-9d3d2dbacf08"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1044897 training questions.\n",
      "Found 261225 validation questions.\n",
      "Found 56370 test questions.\n"
     ]
    }
   ],
   "source": [
    "X_train = train_df['treated_question'].fillna('+++').tolist()\n",
    "X_val = val_df['treated_question'].fillna('+++').tolist()\n",
    "X_test = test_df['treated_question'].fillna('+++').tolist()\n",
    "\n",
    "y_train = train_df['target']\n",
    "y_val = val_df['target']\n",
    "\n",
    "print('Found %s training questions.' % len(X_train))\n",
    "print('Found %s validation questions.' % len(X_val))\n",
    "print('Found %s test questions.' % len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "_uuid": "d9bb5e7c69abf941c142775505c87fb8804f6345",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "_kbWqXCezaBA",
    "outputId": "79004f92-5f67-4ceb-caf0-01a78506cb9f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (1044897, 250)\n",
      "Shape of y_train: (1044897,)\n",
      "Found 174033 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "tokenizer = Tokenizer(num_words=MAX_WORDS, lower=True, split=' ', \n",
    "                       char_level=False, oov_token=None, document_count=0,\n",
    "                      )\n",
    "                                   \n",
    "tokenizer.fit_on_texts(X_train)\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_train = pad_sequences(X_train, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "X_val = tokenizer.texts_to_sequences(X_val)\n",
    "X_val = pad_sequences(X_val, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "X_test = tokenizer.texts_to_sequences(X_test)\n",
    "X_test = pad_sequences(X_test, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "print('Shape of X_train:', X_train.shape)\n",
    "print('Shape of y_train:', y_train.shape)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "print('Found %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "aedafbcf978e9c8eb2db0fa3fc650762f02d87a0",
    "colab_type": "text",
    "id": "BUSd8dmWEUf4"
   },
   "source": [
    "## Save tokenized data + word index (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 76 ms, sys: 1.4 s, total: 1.48 s\n",
      "Wall time: 6.16 s\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "%%time\n",
    "\n",
    "import pickle\n",
    "\n",
    "test_df.to_pickle('test_df.pkl')\n",
    "\n",
    "np.save('X_train.npy', X_train)\n",
    "np.save('X_val.npy', X_val)\n",
    "np.save('X_test.npy', X_test)\n",
    "\n",
    "y_train.to_pickle('y_train.pkl')\n",
    "y_val.to_pickle('y_val.pkl')\n",
    "\n",
    "pickle.dump(word_index, open('word_index.pkl', 'wb'))\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "aedafbcf978e9c8eb2db0fa3fc650762f02d87a0",
    "colab_type": "text",
    "id": "BUSd8dmWEUf4"
   },
   "source": [
    "## Build vocabulary with counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "_uuid": "860e94814f74b4282fce01a2c8c42d7c29d1dabf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.14 s, sys: 544 ms, total: 9.69 s\n",
      "Wall time: 9.69 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "vocab = build_vocab(pd.concat([train_df['treated_question'], val_df['treated_question'], test_df['treated_question']]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e1d40498bd469f8c5784570ddb88bb65a6367064",
    "colab_type": "text",
    "id": "BUSd8dmWEUf4"
   },
   "source": [
    "## Load embeddings, measure coverage and save embedding matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "_uuid": "2801e906d9eb5bc96c231cf1e3d577a160d8d289",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "YfAhNjEJEXmN",
    "outputId": "58618a30-4fab-44f0-8dec-591a8df2da47"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glove:\n",
      "Loading embeddings from: ../input/embeddings/glove.840B.300d/glove.840B.300d.txt\n",
      "Found 2195892 word vectors.\n",
      "Found embeddings for 63.10% of vocab\n",
      "Found embeddings for  99.39% of all text\n",
      "CPU times: user 2min 42s, sys: 6.71 s, total: 2min 49s\n",
      "Wall time: 2min 49s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "print('glove:')\n",
    "glove_path = '../input/embeddings/glove.840B.300d/glove.840B.300d.txt'\n",
    "embeddings_index = loadEmbeddings(glove_path, EMBEDDING_DIM)\n",
    "check_coverage(vocab, embeddings_index)\n",
    "embedding_matrix = getEmbeddingMatrix(embeddings_index, word_index)\n",
    "del embeddings_index\n",
    "np.save('glove.npy', embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "_uuid": "889bc1ae4af9fe032c72e8c8c606ae5b1d66f7d8",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "YfAhNjEJEXmN",
    "outputId": "58618a30-4fab-44f0-8dec-591a8df2da47"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "paragram:\n",
      "Loading embeddings from: ../input/embeddings/paragram_300_sl999/paragram_300_sl999.txt\n",
      "Found 1703663 word vectors.\n",
      "Found embeddings for 74.06% of vocab\n",
      "Found embeddings for  99.64% of all text\n"
     ]
    }
   ],
   "source": [
    "print('paragram:')\n",
    "paragram_path = '../input/embeddings/paragram_300_sl999/paragram_300_sl999.txt'\n",
    "embeddings_index = loadEmbeddings(paragram_path, EMBEDDING_DIM, encoding='utf8', errors='ignore')\n",
    "check_coverage(vocab, embeddings_index)\n",
    "embedding_matrix = getEmbeddingMatrix(embeddings_index, word_index)\n",
    "del embeddings_index\n",
    "np.save('paragram.npy', embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "_uuid": "79b0a76992718f29aec733bec9f59beb85302a31",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "YfAhNjEJEXmN",
    "outputId": "58618a30-4fab-44f0-8dec-591a8df2da47"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wiki:\n",
      "Loading embeddings from: ../input/embeddings/wiki-news-300d-1M/wiki-news-300d-1M.vec\n",
      "Found 999994 word vectors.\n",
      "Found embeddings for 48.05% of vocab\n",
      "Found embeddings for  98.81% of all text\n"
     ]
    }
   ],
   "source": [
    "print('wiki:')\n",
    "wiki_path = '../input/embeddings/wiki-news-300d-1M/wiki-news-300d-1M.vec'\n",
    "embeddings_index = loadEmbeddings(wiki_path, EMBEDDING_DIM)\n",
    "check_coverage(vocab, embeddings_index)\n",
    "embedding_matrix = getEmbeddingMatrix(embeddings_index, word_index)\n",
    "del embeddings_index\n",
    "np.save('wiki.npy', embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "_uuid": "c1ec208ac42fbf73e8213442f1333cbf18791a16"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "google_news:\n",
      "Loading embeddings from: ../input/embeddings/GoogleNews-vectors-negative300/GoogleNews-vectors-negative300.bin\n",
      "Found 3000000 word vectors.\n",
      "Found embeddings for 38.68% of vocab\n",
      "Found embeddings for  78.84% of all text\n"
     ]
    }
   ],
   "source": [
    "print('google_news:')\n",
    "google_news_path = '../input/embeddings/GoogleNews-vectors-negative300/GoogleNews-vectors-negative300.bin'\n",
    "embeddings_index = loadEmbeddingsGensim(google_news_path, EMBEDDING_DIM)\n",
    "check_coverage(vocab, embeddings_index)\n",
    "embedding_matrix = getEmbeddingMatrix(embeddings_index, word_index)\n",
    "del embeddings_index\n",
    "np.save('google_news.npy', embedding_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "380e34c9a8b4a797b10cb54e15760a9dd7b28ae0",
    "colab_type": "text",
    "id": "BUSd8dmWEUf4"
   },
   "source": [
    "# Oversample training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "_uuid": "47c26457a2b8c17015bf5c5c60cbb562fe199429"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom imblearn.over_sampling import SMOTE\\n\\nsm = SMOTE(random_state=42, ratio = 1.0)\\nX_train, y_train = sm.fit_sample(X_train, y_train)\\n'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "sm = SMOTE(random_state=42, ratio = 1.0)\n",
    "X_train, y_train = sm.fit_sample(X_train, y_train)\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "_uuid": "f28b53680bc8874337b09a61887d6c74da683659"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nbalanced_train_df = pd.DataFrame()\\nbalanced_train_df[0] = np.array(y_train)\\n\\ntarget_ratios = balanced_train_df[0].value_counts(normalize=True)\\n\\nprint(target_ratios)\\n\\ntarget_ratios.plot(kind='bar', title='Ratios after SMOTE (target)')\\n\""
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "balanced_train_df = pd.DataFrame()\n",
    "balanced_train_df[0] = np.array(y_train)\n",
    "\n",
    "target_ratios = balanced_train_df[0].value_counts(normalize=True)\n",
    "\n",
    "print(target_ratios)\n",
    "\n",
    "target_ratios.plot(kind='bar', title='Ratios after SMOTE (target)')\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "fab17b9cec7b6c69d9b96bfc5731882a1216d788",
    "colab_type": "text",
    "id": "aNd1KcNjsvxj"
   },
   "source": [
    "# Setup model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aNd1KcNjsvxj"
   },
   "source": [
    "# Restore point (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 68 ms, sys: 1.02 s, total: 1.08 s\n",
      "Wall time: 1.08 s\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "%%time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "test_df = pd.read_pickle('test_df.pkl')\n",
    "\n",
    "X_train = np.load('X_train.npy')\n",
    "X_val = np.load('X_val.npy')\n",
    "X_test = np.load('X_test.npy')\n",
    "\n",
    "y_train = pd.read_pickle('y_train.pkl')\n",
    "y_val = pd.read_pickle('y_val.pkl')\n",
    "\n",
    "word_index = pickle.load(open('word_index.pkl', 'rb'))\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d45a12e7532c1ff87d68b626baada8a5bbe6b0fe",
    "colab_type": "text",
    "id": "BUSd8dmWEUf4"
   },
   "source": [
    "## Embeddings Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "_uuid": "48576619ba4f1847df5ea12bdd11b24b3920b25d"
   },
   "outputs": [],
   "source": [
    "from keras.layers import Embedding\n",
    "\n",
    "embedding_layers = {}\n",
    "\n",
    "embedding_matrix = np.load('glove.npy')\n",
    "embedding_layers['glove'] = Embedding(MAX_WORDS, EMBEDDING_DIM, weights=[embedding_matrix], input_length=MAX_SEQUENCE_LENGTH, trainable=False)\n",
    "\n",
    "embedding_matrix = np.load('paragram.npy')\n",
    "embedding_layers['paragram'] = Embedding(MAX_WORDS, EMBEDDING_DIM, weights=[embedding_matrix], input_length=MAX_SEQUENCE_LENGTH, trainable=False)\n",
    "\n",
    "embedding_matrix = np.load('wiki.npy')\n",
    "embedding_layers['wiki'] = Embedding(MAX_WORDS, EMBEDDING_DIM, weights=[embedding_matrix], input_length=MAX_SEQUENCE_LENGTH, trainable=False)\n",
    "\n",
    "embedding_matrix = np.load('google_news.npy')\n",
    "embedding_layers['google_news'] = Embedding(MAX_WORDS, EMBEDDING_DIM, weights=[embedding_matrix], input_length=MAX_SEQUENCE_LENGTH, trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "_uuid": "7711de071093e6c256b2e8bf68fe64e9436ba0e2"
   },
   "outputs": [],
   "source": [
    "del word_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "60a8b6ecb457fff127b4f7db954c42c63fa68b76",
    "colab_type": "text",
    "id": "BUSd8dmWEUf4"
   },
   "source": [
    "## NN: Bidirectional GRU per embedding with concactenation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "_uuid": "2d9a7a2733cee240d25312c05c08d41e0d6c4976"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 250)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 250, 300)     30000000    input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 250, 300)     30000000    input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, 250, 300)     30000000    input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_9 (Bidirectional) (None, 250, 128)     140544      embedding_1[2][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_10 (Bidirectional (None, 250, 128)     140544      embedding_2[2][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_11 (Bidirectional (None, 250, 128)     140544      embedding_3[2][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 250, 128)     512         bidirectional_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 250, 128)     512         bidirectional_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 250, 128)     512         bidirectional_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_9 (GlobalM (None, 128)          0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_10 (Global (None, 128)          0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_11 (Global (None, 128)          0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 16)           2048        global_max_pooling1d_9[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 16)           2048        global_max_pooling1d_10[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 16)           2048        global_max_pooling1d_11[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 16)           64          dense_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 16)           64          dense_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 16)           64          dense_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 16)           0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 16)           0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 16)           0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 16)           0           activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 16)           0           activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 16)           0           activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 48)           0           dropout_9[0][0]                  \n",
      "                                                                 dropout_10[0][0]                 \n",
      "                                                                 dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 32)           1536        concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 32)           128         dense_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 32)           0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 1)            32          activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 1)            4           dense_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 1)            0           batch_normalization_22[0][0]     \n",
      "==================================================================================================\n",
      "Total params: 90,431,204\n",
      "Trainable params: 430,274\n",
      "Non-trainable params: 90,000,930\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "CPU times: user 2.52 s, sys: 1.43 s, total: 3.94 s\n",
      "Wall time: 1.88 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "from keras.layers import Dense, Dropout, Input, GlobalMaxPool1D\n",
    "from keras.layers import Conv1D, MaxPooling1D, Embedding, Bidirectional\n",
    "from keras.layers import Activation, BatchNormalization, CuDNNGRU\n",
    "from keras.layers import SpatialDropout1D, Concatenate, Flatten, Reshape\n",
    "from keras.regularizers import l2\n",
    "from keras.models import Model\n",
    "\n",
    "\n",
    "inp = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "\n",
    "a = embedding_layers['glove'] (inp)\n",
    "a = Bidirectional(CuDNNGRU(64, return_sequences=True))(a)\n",
    "a = BatchNormalization()(a)\n",
    "a = GlobalMaxPool1D()(a)\n",
    "a = Dense(16, use_bias=False)(a)\n",
    "a = BatchNormalization()(a)\n",
    "a = Activation(\"relu\")(a)\n",
    "a = Dropout(0.1)(a)\n",
    "\n",
    "b = embedding_layers['paragram'] (inp)\n",
    "b = Bidirectional(CuDNNGRU(64, return_sequences=True))(b)\n",
    "b = BatchNormalization()(b)\n",
    "b = GlobalMaxPool1D()(b)\n",
    "b = Dense(16, use_bias=False)(b)\n",
    "b = BatchNormalization()(b)\n",
    "b = Activation(\"relu\")(b)\n",
    "b = Dropout(0.1)(b)\n",
    "\n",
    "c = embedding_layers['wiki'] (inp)\n",
    "c = Bidirectional(CuDNNGRU(64, return_sequences=True))(c)\n",
    "c = BatchNormalization()(c)\n",
    "c = GlobalMaxPool1D()(c)\n",
    "c = Dense(16, use_bias=False)(c)\n",
    "c = BatchNormalization()(c)\n",
    "c = Activation(\"relu\")(c)\n",
    "c = Dropout(0.1)(c)\n",
    "\n",
    "d = embedding_layers['google_news'] (inp)\n",
    "d = Bidirectional(CuDNNGRU(64, return_sequences=True))(d)\n",
    "d = BatchNormalization()(d)\n",
    "d = GlobalMaxPool1D()(d)\n",
    "d = Dense(16, use_bias=False)(d)\n",
    "d = BatchNormalization()(d)\n",
    "d = Activation(\"relu\")(d)\n",
    "d = Dropout(0.1)(d)\n",
    "\n",
    "x = Concatenate(axis=1)([a, b, c])\n",
    "x = Dense(32, use_bias=False)(x)\n",
    "x = BatchNormalization()(x)\n",
    "#kernel_regularizer=l2(0.01)\n",
    "x = Activation(\"relu\")(x)\n",
    "x = Dense(1, use_bias=False)(x)\n",
    "x = BatchNormalization()(x)\n",
    "out = Activation(\"sigmoid\")(x)\n",
    "\n",
    "model = Model(inp, out)\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "74e7edd06d9d1ef89f4369021b8ce094be9e21db",
    "colab_type": "text",
    "id": "Lp4o2h9Fs8gP"
   },
   "source": [
    "# Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "_uuid": "fafbbea8029e31d17a3f731639bbc62970e4e1b0",
    "colab": {},
    "colab_type": "code",
    "id": "L75Rc0Gqtclm"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1d1c4d092bca6f093254b5792c4b8801c1282b0f",
    "colab_type": "text",
    "id": "NVFKqCPUtJcy"
   },
   "source": [
    "# Train the model\n",
    "\n",
    "Use model checkpointing to save the model that attains the best validation loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "_uuid": "2db478168d542638ce5cb6358de7ebd503d000b0",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "3OwX8ErsteZL",
    "outputId": "f718108c-5f78-4d9b-8814-c7044a9cce96"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1044897 samples, validate on 261225 samples\n",
      "Epoch 1/1\n",
      "1044897/1044897 [==============================] - 386s 370us/step - loss: 0.1150 - acc: 0.9618 - val_loss: 0.1084 - val_acc: 0.9601\n",
      "CPU times: user 5min 15s, sys: 50.3 s, total: 6min 5s\n",
      "Wall time: 6min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "hist = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=1, batch_size=512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "926710a7b8364a65a6ea5bdb8f103462b622549c",
    "colab_type": "text",
    "id": "NVFKqCPUtJcy"
   },
   "source": [
    "# Predict validation labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "_uuid": "80dbd1aae9b5ec74071b7a11de96abee7cd2ad66"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "261225/261225 [==============================] - 22s 86us/step\n",
      "CPU times: user 20.5 s, sys: 4.69 s, total: 25.2 s\n",
      "Wall time: 22.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "pred_val = model.predict([X_val], batch_size=1024, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "fbe1a9626a625a4540b35fe646af0d78e8952b24",
    "colab_type": "text",
    "id": "NVFKqCPUtJcy"
   },
   "source": [
    "# Find best threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "_uuid": "c5861eb15765c20d4a5be5892543520bdb006bfa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current threshold is 0.1000 with F1 score: 0.5991\n",
      "Current threshold is 0.1100 with F1 score: 0.6110\n",
      "Current threshold is 0.1200 with F1 score: 0.6214\n",
      "Current threshold is 0.1300 with F1 score: 0.6302\n",
      "Current threshold is 0.1400 with F1 score: 0.6376\n",
      "Current threshold is 0.1500 with F1 score: 0.6442\n",
      "Current threshold is 0.1600 with F1 score: 0.6496\n",
      "Current threshold is 0.1700 with F1 score: 0.6539\n",
      "Current threshold is 0.1800 with F1 score: 0.6583\n",
      "Current threshold is 0.1900 with F1 score: 0.6621\n",
      "Current threshold is 0.2000 with F1 score: 0.6656\n",
      "Current threshold is 0.2100 with F1 score: 0.6678\n",
      "Current threshold is 0.2200 with F1 score: 0.6689\n",
      "Current threshold is 0.2300 with F1 score: 0.6705\n",
      "Current threshold is 0.2400 with F1 score: 0.6719\n",
      "Current threshold is 0.2500 with F1 score: 0.6735\n",
      "Current threshold is 0.2600 with F1 score: 0.6734\n",
      "Current threshold is 0.2700 with F1 score: 0.6733\n",
      "Current threshold is 0.2800 with F1 score: 0.6733\n",
      "Current threshold is 0.2900 with F1 score: 0.6740\n",
      "Current threshold is 0.3000 with F1 score: 0.6729\n",
      "Current threshold is 0.3100 with F1 score: 0.6727\n",
      "Current threshold is 0.3200 with F1 score: 0.6704\n",
      "Current threshold is 0.3300 with F1 score: 0.6696\n",
      "Current threshold is 0.3400 with F1 score: 0.6682\n",
      "Current threshold is 0.3500 with F1 score: 0.6672\n",
      "Current threshold is 0.3600 with F1 score: 0.6659\n",
      "Current threshold is 0.3700 with F1 score: 0.6633\n",
      "Current threshold is 0.3800 with F1 score: 0.6596\n",
      "Current threshold is 0.3900 with F1 score: 0.6561\n",
      "Current threshold is 0.4000 with F1 score: 0.6529\n",
      "Current threshold is 0.4100 with F1 score: 0.6478\n",
      "Current threshold is 0.4200 with F1 score: 0.6444\n",
      "Current threshold is 0.4300 with F1 score: 0.6402\n",
      "Current threshold is 0.4400 with F1 score: 0.6362\n",
      "Current threshold is 0.4500 with F1 score: 0.6311\n",
      "Current threshold is 0.4600 with F1 score: 0.6271\n",
      "Current threshold is 0.4700 with F1 score: 0.6227\n",
      "Current threshold is 0.4800 with F1 score: 0.6172\n",
      "Current threshold is 0.4900 with F1 score: 0.6123\n",
      "Current threshold is 0.5000 with F1 score: 0.6063\n",
      "best threshold is 0.2900 with F1 score: 0.6740\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def bestThreshold(y_true,y_pred):\n",
    "    idx = 0\n",
    "    cur_f1 = 0\n",
    "    max_f1 = 0\n",
    "    thres = 0\n",
    "    for idx in np.arange(0.1, 0.501, 0.01):\n",
    "        cur_f1 = f1_score(y_true, np.array(y_pred)> idx)\n",
    "        print('Current threshold is {:.4f} with F1 score: {:.4f}'.format(idx, cur_f1))\n",
    "        if cur_f1 > max_f1:\n",
    "            max_f1 = cur_f1\n",
    "            thres = idx\n",
    "    print('best threshold is {:.4f} with F1 score: {:.4f}'.format(thres, max_f1))\n",
    "    return thres\n",
    "threshold = bestThreshold(y_val,pred_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "_uuid": "0ff585d4c11ae673051881795e74ff97d8d2b4c8"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(hist.history['acc'], label='Train Accuracy')\n",
    "plt.plot(hist.history['val_acc'], label='Test Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NVFKqCPUtJcy"
   },
   "source": [
    "# serialize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "model.save('model.h5')\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NVFKqCPUtJcy"
   },
   "source": [
    "# serialize weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model weights to disk\n"
     ]
    }
   ],
   "source": [
    "model.save_weights(\"weights.h5\")\n",
    "print(\"Saved model weights to disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d377f47a86a67e1b60bf83efa2e85c08e87281dd",
    "colab_type": "text",
    "id": "NVFKqCPUtJcy"
   },
   "source": [
    "# Predict test labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "_uuid": "0670f1a7c1ed5cfd85d049dfc0ef1681aaab055b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56370/56370 [==============================] - 5s 86us/step\n",
      "CPU times: user 4.41 s, sys: 1.02 s, total: 5.44 s\n",
      "Wall time: 4.85 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "pred_test = model.predict([X_test], batch_size=1024, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f3c1ff0ac4324bbf847ed3fdafe4db682d833f8a",
    "colab_type": "text",
    "id": "NVFKqCPUtJcy"
   },
   "source": [
    "# Prepare submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "_uuid": "7f3601299112b7d1ea815db80243344ace06ca42"
   },
   "outputs": [],
   "source": [
    "submission_df = pd.DataFrame({\"qid\":test_df[\"qid\"].values})\n",
    "submission_df['prediction'] = (pred_test > threshold).astype(int)\n",
    "submission_df.to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "capstone.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
