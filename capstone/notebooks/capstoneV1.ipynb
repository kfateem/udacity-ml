{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "749cb0b7d343d12569698ece840039c7fef54711",
    "colab_type": "text",
    "id": "BUSd8dmWEUf4"
   },
   "source": [
    "# Capstone V1 model\n",
    "\n",
    "This is a GRU model with an untrained embedding layer.\n",
    "The validation F1-score is 0.6379 at a threshold of 0.30."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "85c12f788178232533cbf7f141e217c32b882cda",
    "colab_type": "text",
    "id": "w7oagxHHofxb"
   },
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "f0421d98769ce1b3bcc0b65f729851be0d275cb5"
   },
   "outputs": [],
   "source": [
    "MAX_SEQUENCE_LENGTH = 100\n",
    "EMBEDDING_DIM = 300\n",
    "MAX_WORDS = 50000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "70e187637082e5f448863c5f965fff8ab80ed065",
    "colab_type": "text",
    "id": "w7oagxHHofxb"
   },
   "source": [
    "# Import test/train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "e20e43f9ea433ee2eee88003355ef86f724fa01c",
    "colab": {},
    "colab_type": "code",
    "id": "X3n8bRW6WcKo"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "train_df = pd.read_csv(\"../input/train.csv\")\n",
    "test_df = pd.read_csv(\"../input/test.csv\")\n",
    "\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.max_rows = None\n",
    "pd.options.display.max_colwidth = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "21e24633c2528b71fc434bf528f7b29fbed63f25",
    "colab_type": "text",
    "id": "QIn-67cmvDFk"
   },
   "source": [
    "## Split train/validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "3a4e4292f236ac2a779968bb38239e61e5f48eab"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ab9fc29433d90e5d99d5fe728bb92d3c613a1e9f",
    "colab_type": "text",
    "id": "QIn-67cmvDFk"
   },
   "source": [
    "## Fill data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "c3eff454f10f0f7ca9552205a993b094fa5b5c57",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "bbmOu7FPvNgI",
    "outputId": "653bd496-0185-474a-d557-9d3d2dbacf08"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1044897 training questions.\n",
      "Found 261225 validation questions.\n",
      "Found 56370 test questions.\n"
     ]
    }
   ],
   "source": [
    "X_train = train_df['question_text'].fillna('+++').tolist()\n",
    "X_val = val_df['question_text'].fillna('+++').tolist()\n",
    "X_test = test_df['question_text'].fillna('+++').tolist()\n",
    "\n",
    "y_train = train_df['target']\n",
    "y_val = val_df['target']\n",
    "\n",
    "print('Found %s training questions.' % len(X_train))\n",
    "print('Found %s validation questions.' % len(X_val))\n",
    "print('Found %s test questions.' % len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "d9bb5e7c69abf941c142775505c87fb8804f6345",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "_kbWqXCezaBA",
    "outputId": "79004f92-5f67-4ceb-caf0-01a78506cb9f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (1044897, 100)\n",
      "Shape of y_train: (1044897,)\n",
      "Found 392005 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "tokenizer = Tokenizer(num_words=MAX_WORDS, lower=True, split=' ', filters='',\n",
    "                       char_level=False, oov_token=None, document_count=0,\n",
    "                     )\n",
    "                                   \n",
    "tokenizer.fit_on_texts(X_train)\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_train = pad_sequences(X_train, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "X_val = tokenizer.texts_to_sequences(X_val)\n",
    "X_val = pad_sequences(X_val, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "X_test = tokenizer.texts_to_sequences(X_test)\n",
    "X_test = pad_sequences(X_test, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "print('Shape of X_train:', X_train.shape)\n",
    "print('Shape of y_train:', y_train.shape)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "print('Found %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "60a8b6ecb457fff127b4f7db954c42c63fa68b76",
    "colab_type": "text",
    "id": "BUSd8dmWEUf4"
   },
   "source": [
    "## NN: Bidirectional GRU per embedding with concactenation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "2d9a7a2733cee240d25312c05c08d41e0d6c4976"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 100, 300)          15000000  \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 100, 128)          140544    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 17        \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 15,145,217\n",
      "Trainable params: 15,145,217\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "CPU times: user 6.02 s, sys: 404 ms, total: 6.42 s\n",
      "Wall time: 5.98 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "from keras.layers import Dense, Dropout, Input, GlobalMaxPool1D\n",
    "from keras.layers import Conv1D, MaxPooling1D, Embedding, Bidirectional\n",
    "from keras.layers import Activation, BatchNormalization, CuDNNGRU\n",
    "from keras.layers import SpatialDropout1D, Concatenate, Flatten, Reshape\n",
    "from keras.regularizers import l2\n",
    "from keras.models import Model\n",
    "\n",
    "\n",
    "inp = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "x = Embedding(MAX_WORDS, EMBEDDING_DIM, input_length=MAX_SEQUENCE_LENGTH) (inp)\n",
    "x = Bidirectional(CuDNNGRU(64, return_sequences=True))(x)\n",
    "x = GlobalMaxPool1D()(x)\n",
    "x = Dense(32)(x)\n",
    "x = Activation(\"relu\")(x)\n",
    "x = Dropout(0.1)(x)\n",
    "x = Dense(16)(x)\n",
    "x = Activation(\"relu\")(x)\n",
    "x = Dropout(0.1)(x)\n",
    "x = Dense(1)(x)\n",
    "out = Activation(\"sigmoid\")(x)\n",
    "\n",
    "model = Model(inp, out)\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    " \n",
    "def f1(y_true, y_pred):\n",
    "    p = precision(y_true, y_pred)\n",
    "    r = recall(y_true, y_pred)\n",
    "    return 2*((p*r)/(p+r+K.epsilon()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "74e7edd06d9d1ef89f4369021b8ce094be9e21db",
    "colab_type": "text",
    "id": "Lp4o2h9Fs8gP"
   },
   "source": [
    "# Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "fafbbea8029e31d17a3f731639bbc62970e4e1b0",
    "colab": {},
    "colab_type": "code",
    "id": "L75Rc0Gqtclm"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy', f1, recall, precision])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NVFKqCPUtJcy"
   },
   "source": [
    "# serialize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "model.save('capstoneV1.model.h5')\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aNd1KcNjsvxj"
   },
   "source": [
    "# Setup f1-score, precision and recall metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "checkpoints = ModelCheckpoint('capstoneV1.weights_checkpoint.h5', monitor=\"val_f1\", mode=\"max\", verbose=True, save_best_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1d1c4d092bca6f093254b5792c4b8801c1282b0f",
    "colab_type": "text",
    "id": "NVFKqCPUtJcy"
   },
   "source": [
    "# Train the model\n",
    "\n",
    "Use model checkpointing to save the model that attains the best validation loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "2db478168d542638ce5cb6358de7ebd503d000b0",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "3OwX8ErsteZL",
    "outputId": "f718108c-5f78-4d9b-8814-c7044a9cce96"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1044897 samples, validate on 261225 samples\n",
      "Epoch 1/2\n",
      "1044897/1044897 [==============================] - 90s 86us/step - loss: 0.1258 - acc: 0.9523 - f1: 0.5287 - recall: 0.4591 - precision: 0.6626 - val_loss: 0.1097 - val_acc: 0.9570 - val_f1: 0.6056 - val_recall: 0.5635 - val_precision: 0.6766\n",
      "\n",
      "Epoch 00001: val_f1 improved from -inf to 0.60559, saving model to capstoneV1.weights_checkpoint.h5\n",
      "Epoch 2/2\n",
      "1044897/1044897 [==============================] - 87s 83us/step - loss: 0.0993 - acc: 0.9606 - f1: 0.6448 - recall: 0.5978 - precision: 0.7237 - val_loss: 0.1095 - val_acc: 0.9571 - val_f1: 0.5701 - val_recall: 0.4882 - val_precision: 0.7186\n",
      "\n",
      "Epoch 00002: val_f1 did not improve from 0.60559\n",
      "CPU times: user 3min 10s, sys: 29.2 s, total: 3min 40s\n",
      "Wall time: 2min 58s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "hist = model.fit(X_train, y_train, validation_data=(X_val, y_val), callbacks=[checkpoints], epochs=2, batch_size=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "926710a7b8364a65a6ea5bdb8f103462b622549c",
    "colab_type": "text",
    "id": "NVFKqCPUtJcy"
   },
   "source": [
    "# Predict validation labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "80dbd1aae9b5ec74071b7a11de96abee7cd2ad66"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "261225/261225 [==============================] - 3s 10us/step\n",
      "CPU times: user 2.66 s, sys: 468 ms, total: 3.13 s\n",
      "Wall time: 2.61 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "pred_val = model.predict([X_val], batch_size=1024, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "fbe1a9626a625a4540b35fe646af0d78e8952b24",
    "colab_type": "text",
    "id": "NVFKqCPUtJcy"
   },
   "source": [
    "# Find optimal threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "c5861eb15765c20d4a5be5892543520bdb006bfa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current threshold is 0.1000 with F1 score: 0.5501, Recall score: 0.8652, Precision score: 0.4032\n",
      "Current threshold is 0.1100 with F1 score: 0.5611, Recall score: 0.8563, Precision score: 0.4172\n",
      "Current threshold is 0.1200 with F1 score: 0.5711, Recall score: 0.8483, Precision score: 0.4305\n",
      "Current threshold is 0.1300 with F1 score: 0.5791, Recall score: 0.8394, Precision score: 0.4421\n",
      "Current threshold is 0.1400 with F1 score: 0.5871, Recall score: 0.8303, Precision score: 0.4541\n",
      "Current threshold is 0.1500 with F1 score: 0.5948, Recall score: 0.8206, Precision score: 0.4664\n",
      "Current threshold is 0.1600 with F1 score: 0.6007, Recall score: 0.8104, Precision score: 0.4772\n",
      "Current threshold is 0.1700 with F1 score: 0.6067, Recall score: 0.8012, Precision score: 0.4881\n",
      "Current threshold is 0.1800 with F1 score: 0.6119, Recall score: 0.7914, Precision score: 0.4988\n",
      "Current threshold is 0.1900 with F1 score: 0.6156, Recall score: 0.7803, Precision score: 0.5083\n",
      "Current threshold is 0.2000 with F1 score: 0.6203, Recall score: 0.7718, Precision score: 0.5185\n",
      "Current threshold is 0.2100 with F1 score: 0.6245, Recall score: 0.7629, Precision score: 0.5286\n",
      "Current threshold is 0.2200 with F1 score: 0.6278, Recall score: 0.7539, Precision score: 0.5378\n",
      "Current threshold is 0.2300 with F1 score: 0.6300, Recall score: 0.7434, Precision score: 0.5467\n",
      "Current threshold is 0.2400 with F1 score: 0.6319, Recall score: 0.7341, Precision score: 0.5547\n",
      "Current threshold is 0.2500 with F1 score: 0.6341, Recall score: 0.7246, Precision score: 0.5636\n",
      "Current threshold is 0.2600 with F1 score: 0.6357, Recall score: 0.7149, Precision score: 0.5722\n",
      "Current threshold is 0.2700 with F1 score: 0.6369, Recall score: 0.7057, Precision score: 0.5803\n",
      "Current threshold is 0.2800 with F1 score: 0.6371, Recall score: 0.6954, Precision score: 0.5878\n",
      "Current threshold is 0.2900 with F1 score: 0.6376, Recall score: 0.6864, Precision score: 0.5953\n",
      "Current threshold is 0.3000 with F1 score: 0.6379, Recall score: 0.6794, Precision score: 0.6013\n",
      "Current threshold is 0.3100 with F1 score: 0.6366, Recall score: 0.6696, Precision score: 0.6067\n",
      "Current threshold is 0.3200 with F1 score: 0.6364, Recall score: 0.6615, Precision score: 0.6131\n",
      "Current threshold is 0.3300 with F1 score: 0.6351, Recall score: 0.6515, Precision score: 0.6195\n",
      "Current threshold is 0.3400 with F1 score: 0.6337, Recall score: 0.6423, Precision score: 0.6254\n",
      "Current threshold is 0.3500 with F1 score: 0.6326, Recall score: 0.6329, Precision score: 0.6323\n",
      "Current threshold is 0.3600 with F1 score: 0.6317, Recall score: 0.6247, Precision score: 0.6389\n",
      "Current threshold is 0.3700 with F1 score: 0.6292, Recall score: 0.6147, Precision score: 0.6444\n",
      "Current threshold is 0.3800 with F1 score: 0.6269, Recall score: 0.6039, Precision score: 0.6517\n",
      "Current threshold is 0.3900 with F1 score: 0.6244, Recall score: 0.5947, Precision score: 0.6572\n",
      "Current threshold is 0.4000 with F1 score: 0.6216, Recall score: 0.5848, Precision score: 0.6633\n",
      "Current threshold is 0.4100 with F1 score: 0.6194, Recall score: 0.5759, Precision score: 0.6701\n",
      "Current threshold is 0.4200 with F1 score: 0.6157, Recall score: 0.5653, Precision score: 0.6760\n",
      "Current threshold is 0.4300 with F1 score: 0.6120, Recall score: 0.5551, Precision score: 0.6817\n",
      "Current threshold is 0.4400 with F1 score: 0.6085, Recall score: 0.5459, Precision score: 0.6874\n",
      "Current threshold is 0.4500 with F1 score: 0.6035, Recall score: 0.5350, Precision score: 0.6922\n",
      "Current threshold is 0.4600 with F1 score: 0.5995, Recall score: 0.5256, Precision score: 0.6975\n",
      "Current threshold is 0.4700 with F1 score: 0.5958, Recall score: 0.5170, Precision score: 0.7030\n",
      "Current threshold is 0.4800 with F1 score: 0.5909, Recall score: 0.5076, Precision score: 0.7067\n",
      "Current threshold is 0.4900 with F1 score: 0.5855, Recall score: 0.4976, Precision score: 0.7111\n",
      "Current threshold is 0.5000 with F1 score: 0.5799, Recall score: 0.4872, Precision score: 0.7161\n",
      "optimal threshold is 0.3000 with F1 score: 0.6379\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "\n",
    "def optimalThreshold(y_true,y_pred):\n",
    "    idx = 0\n",
    "    cur_f1 = 0\n",
    "    cur_prec = 0\n",
    "    cur_recall = 0\n",
    "    max_f1 = 0\n",
    "    thres = 0\n",
    "    for idx in np.arange(0.1, 0.501, 0.01):\n",
    "        cur_f1 = f1_score(y_true, np.array(y_pred)> idx)\n",
    "        cur_recall = recall_score(y_true, np.array(y_pred)> idx)\n",
    "        cur_prec = precision_score(y_true, np.array(y_pred)> idx)\n",
    "        print('Current threshold is {:.4f} with F1 score: {:.4f}, Recall score: {:.4f}, Precision score: {:.4f}'\n",
    "              .format(idx, cur_f1, cur_recall, cur_prec)\n",
    "             )\n",
    "        if cur_f1 > max_f1:\n",
    "            max_f1 = cur_f1\n",
    "            thres = idx\n",
    "    print('optimal threshold is {:.4f} with F1 score: {:.4f}'.format(thres, max_f1))\n",
    "    return thres\n",
    "threshold = optimalThreshold(y_val,pred_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "print(classification_report(y_val, np.array(pred_val > threshold).astype(int), target_names=['sincere', 'insincere']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "cm = confusion_matrix(y_val, np.array(pred_val > threshold).astype(int))\n",
    "ax = plt.subplot()\n",
    "hm = sns.heatmap(cm, annot=True, ax = ax, fmt='g', \n",
    "                 cmap=ListedColormap(['white']), linecolor='black', \n",
    "                 linewidth=1, cbar=False,\n",
    "                 xticklabels = 1, yticklabels = 1 )\n",
    "\n",
    "\n",
    "# labels, title and ticks\n",
    "ax.set_xlabel('Predicted labels')\n",
    "ax.set_ylabel('True labels') \n",
    "ax.set_title('Confusion Matrix')\n",
    "ax.xaxis.set_ticklabels(['sincere', 'insincere'])\n",
    "ax.yaxis.set_ticklabels(['sincere', 'insincere'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0ff585d4c11ae673051881795e74ff97d8d2b4c8"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "plt.title('model accuracy')\n",
    "plt.plot(hist.history['acc'])\n",
    "plt.plot(hist.history['val_acc'])\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0ff585d4c11ae673051881795e74ff97d8d2b4c8"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "plt.title('model loss')\n",
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0ff585d4c11ae673051881795e74ff97d8d2b4c8"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "plt.title('model F1-score')\n",
    "plt.plot(hist.history['f1'])\n",
    "plt.plot(hist.history['val_f1'])\n",
    "plt.ylabel('f1 score')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NVFKqCPUtJcy"
   },
   "source": [
    "# serialize weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"capstoneV1.weights.h5\")\n",
    "print(\"Saved model weights to disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d377f47a86a67e1b60bf83efa2e85c08e87281dd",
    "colab_type": "text",
    "id": "NVFKqCPUtJcy"
   },
   "source": [
    "# Predict test labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0670f1a7c1ed5cfd85d049dfc0ef1681aaab055b"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "pred_test = model.predict([X_test], batch_size=1024, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f3c1ff0ac4324bbf847ed3fdafe4db682d833f8a",
    "colab_type": "text",
    "id": "NVFKqCPUtJcy"
   },
   "source": [
    "# Analyze predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7f3601299112b7d1ea815db80243344ace06ca42"
   },
   "outputs": [],
   "source": [
    "prediction_df = pd.DataFrame({\"qid\":test_df[\"qid\"].values})\n",
    "prediction_df['prediction'] = (pred_test > threshold).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "\n",
    "pickle_out = open(\"capstoneV1.hist.pkl\",\"wb\")\n",
    "pickle.dump(hist, pickle_out)\n",
    "pickle_out.close()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "capstone.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
