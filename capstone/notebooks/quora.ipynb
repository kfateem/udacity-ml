{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w7oagxHHofxb"
   },
   "source": [
    "# Import dataset in to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X3n8bRW6WcKo"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df = pd.read_csv(\"../input/train.csv\")\n",
    "test_df = pd.read_csv(\"../input/test.csv\")\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.2, random_state=42)\n",
    "\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.max_rows = None\n",
    "pd.options.display.max_colwidth = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w7oagxHHofxb"
   },
   "source": [
    "# Analyze train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 393
    },
    "colab_type": "code",
    "id": "h0aRi6Toaq8j",
    "outputId": "5d5c6246-c8c3-49e0-e8b7-58850a83f62f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample insincere questions\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>question_text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1247862</th>\n",
       "      <td>f48cf262906b4ec1e99b</td>\n",
       "      <td>Do Chinese feel ashamed about their country and want to leave China the way an increasing number of Indians these days do with respect to India?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136091</th>\n",
       "      <td>1aa45bef4748da59ce9c</td>\n",
       "      <td>If Campbell claims that the Russians provided tremendous support to Hillary, how can it be explained that Rosenstein believes the Russians support Trump?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995520</th>\n",
       "      <td>c31636dad39546e27427</td>\n",
       "      <td>Why do girls wear skirts and shorts in public area? Obviously to look attractive, then why they have problem when someone stares them!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608299</th>\n",
       "      <td>771bef59843becc6773d</td>\n",
       "      <td>How do I get over my fear of black men?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>980709</th>\n",
       "      <td>c01d87981ce02afa8d83</td>\n",
       "      <td>Is there any way to get a Muslim cleric declare that Palestinians are fake Muslims?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1187630</th>\n",
       "      <td>e8bbdae1cb950f38979a</td>\n",
       "      <td>I have an intense desire to shoot church choir and alter girls because they show extremely disgusting looks to me?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>602731</th>\n",
       "      <td>760b662bf3bb2a676444</td>\n",
       "      <td>Will Islam ever get banned from Europe? We need to make it happen!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319996</th>\n",
       "      <td>3eb5a0354a76d175bd31</td>\n",
       "      <td>Why are punjabis so aggressive? Why do they get offended so easily?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>683334</th>\n",
       "      <td>85d5b10b163b8adee8df</td>\n",
       "      <td>Why do guys act so innocent at first then suddenly change and want sex?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>824518</th>\n",
       "      <td>a1938e6145b97e7921bf</td>\n",
       "      <td>The path to atheism, is it mind corruption or mental sanitation? Should \"new discoveries\" trouble the mind?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          qid  \\\n",
       "1247862  f48cf262906b4ec1e99b   \n",
       "136091   1aa45bef4748da59ce9c   \n",
       "995520   c31636dad39546e27427   \n",
       "608299   771bef59843becc6773d   \n",
       "980709   c01d87981ce02afa8d83   \n",
       "1187630  e8bbdae1cb950f38979a   \n",
       "602731   760b662bf3bb2a676444   \n",
       "319996   3eb5a0354a76d175bd31   \n",
       "683334   85d5b10b163b8adee8df   \n",
       "824518   a1938e6145b97e7921bf   \n",
       "\n",
       "                                                                                                                                                     question_text  \\\n",
       "1247862  Do Chinese feel ashamed about their country and want to leave China the way an increasing number of Indians these days do with respect to India?            \n",
       "136091   If Campbell claims that the Russians provided tremendous support to Hillary, how can it be explained that Rosenstein believes the Russians support Trump?   \n",
       "995520   Why do girls wear skirts and shorts in public area? Obviously to look attractive, then why they have problem when someone stares them!                      \n",
       "608299   How do I get over my fear of black men?                                                                                                                     \n",
       "980709   Is there any way to get a Muslim cleric declare that Palestinians are fake Muslims?                                                                         \n",
       "1187630  I have an intense desire to shoot church choir and alter girls because they show extremely disgusting looks to me?                                          \n",
       "602731   Will Islam ever get banned from Europe? We need to make it happen!                                                                                          \n",
       "319996   Why are punjabis so aggressive? Why do they get offended so easily?                                                                                         \n",
       "683334   Why do guys act so innocent at first then suddenly change and want sex?                                                                                     \n",
       "824518   The path to atheism, is it mind corruption or mental sanitation? Should \"new discoveries\" trouble the mind?                                                 \n",
       "\n",
       "         target  \n",
       "1247862  1       \n",
       "136091   1       \n",
       "995520   1       \n",
       "608299   1       \n",
       "980709   1       \n",
       "1187630  1       \n",
       "602731   1       \n",
       "319996   1       \n",
       "683334   1       \n",
       "824518   1       "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Sample insincere questions\")\n",
    "train_df.loc[train_df['target'] == 1].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 376
    },
    "colab_type": "code",
    "id": "n_mslOIdaj8G",
    "outputId": "c0c9da0b-96d8-436f-fe37-28a2da1d6b69"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample sincere questions\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>question_text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1044391</th>\n",
       "      <td>cca59fa8481fc990ab7c</td>\n",
       "      <td>My business has $85,000 in yearly contracts and about $165,000 in yearly sales. How would I valuate this?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530479</th>\n",
       "      <td>67dba3131d4a707eef39</td>\n",
       "      <td>How strong was the average Roman soldier in the Roman Empire?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555050</th>\n",
       "      <td>6cc0d8f92cab3f66f7ee</td>\n",
       "      <td>How would you feel or act toward a child if you found out that he knew that his dad hid $350K from you during the divorce - while you are struggling (really hard) right now, to get by while his dad is floating in money?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177787</th>\n",
       "      <td>22c0105412ad0d501e1c</td>\n",
       "      <td>How much \"Political Migration\" from one State to another happens in the US, as in a \"Liberal\" leaving a conservative state for one more representative of a persons political belief or the other way around?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1248780</th>\n",
       "      <td>f4b92aa8f7ef59372f2d</td>\n",
       "      <td>What are the best things for University of Calcutta students to do on weekends?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543151</th>\n",
       "      <td>6a6a605edb5814029877</td>\n",
       "      <td>How can you make a traditional chipotle recipe into a low calorie recipe doing minor alterations?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603791</th>\n",
       "      <td>763ed55f2d93ead2bf3e</td>\n",
       "      <td>What Should drivers do to protesters blocking the road?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>922683</th>\n",
       "      <td>b4cfa7855c2b8d813335</td>\n",
       "      <td>Which companies are present used the asp.net?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109754</th>\n",
       "      <td>157c8e3ff2f5c6fea56a</td>\n",
       "      <td>What if I wanted to play a professional sport and have a working job (like an engineer) when I grow up? Is it possible?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1154620</th>\n",
       "      <td>e23ed77124fae386380a</td>\n",
       "      <td>What are the origins of monkeys?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          qid  \\\n",
       "1044391  cca59fa8481fc990ab7c   \n",
       "530479   67dba3131d4a707eef39   \n",
       "555050   6cc0d8f92cab3f66f7ee   \n",
       "177787   22c0105412ad0d501e1c   \n",
       "1248780  f4b92aa8f7ef59372f2d   \n",
       "543151   6a6a605edb5814029877   \n",
       "603791   763ed55f2d93ead2bf3e   \n",
       "922683   b4cfa7855c2b8d813335   \n",
       "109754   157c8e3ff2f5c6fea56a   \n",
       "1154620  e23ed77124fae386380a   \n",
       "\n",
       "                                                                                                                                                                                                                       question_text  \\\n",
       "1044391  My business has $85,000 in yearly contracts and about $165,000 in yearly sales. How would I valuate this?                                                                                                                     \n",
       "530479   How strong was the average Roman soldier in the Roman Empire?                                                                                                                                                                 \n",
       "555050   How would you feel or act toward a child if you found out that he knew that his dad hid $350K from you during the divorce - while you are struggling (really hard) right now, to get by while his dad is floating in money?   \n",
       "177787   How much \"Political Migration\" from one State to another happens in the US, as in a \"Liberal\" leaving a conservative state for one more representative of a persons political belief or the other way around?                 \n",
       "1248780  What are the best things for University of Calcutta students to do on weekends?                                                                                                                                               \n",
       "543151   How can you make a traditional chipotle recipe into a low calorie recipe doing minor alterations?                                                                                                                             \n",
       "603791   What Should drivers do to protesters blocking the road?                                                                                                                                                                       \n",
       "922683   Which companies are present used the asp.net?                                                                                                                                                                                 \n",
       "109754   What if I wanted to play a professional sport and have a working job (like an engineer) when I grow up? Is it possible?                                                                                                       \n",
       "1154620  What are the origins of monkeys?                                                                                                                                                                                              \n",
       "\n",
       "         target  \n",
       "1044391  0       \n",
       "530479   0       \n",
       "555050   0       \n",
       "177787   0       \n",
       "1248780  0       \n",
       "543151   0       \n",
       "603791   0       \n",
       "922683   0       \n",
       "109754   0       \n",
       "1154620  0       "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Sample sincere questions\")\n",
    "train_df.loc[train_df['target'] == 0].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.937837\n",
      "1    0.062163\n",
      "Name: target, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f70ba9e9908>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "target_ratios = train_df.target.value_counts(normalize=True)\n",
    "\n",
    "print(target_ratios)\n",
    "\n",
    "target_ratios.plot(kind='bar', title='Ratios (target)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average word length of questions in train is 13.\n",
      "Average word length of questions in test is 13.\n"
     ]
    }
   ],
   "source": [
    "print('Average word length of questions in train is {0:.0f}.'.format(np.mean(train_df['question_text'].apply(lambda x: len(x.split())))))\n",
    "print('Average word length of questions in test is {0:.0f}.'.format(np.mean(test_df['question_text'].apply(lambda x: len(x.split())))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max word length of questions in train is 134.\n",
      "Max word length of questions in test is 87.\n"
     ]
    }
   ],
   "source": [
    "print('Max word length of questions in train is {0:.0f}.'.format(np.max(train_df['question_text'].apply(lambda x: len(x.split())))))\n",
    "print('Max word length of questions in test is {0:.0f}.'.format(np.max(test_df['question_text'].apply(lambda x: len(x.split())))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average character length of questions in train is 71.\n",
      "Average character length of questions in test is 70.\n"
     ]
    }
   ],
   "source": [
    "print('Average character length of questions in train is {0:.0f}.'.format(np.mean(train_df['question_text'].apply(lambda x: len(x)))))\n",
    "print('Average character length of questions in test is {0:.0f}.'.format(np.mean(test_df['question_text'].apply(lambda x: len(x)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max character length of questions in train is 1017.\n",
      "Max character length of questions in test is 588.\n"
     ]
    }
   ],
   "source": [
    "print('Max character length of questions in train is {0:.0f}.'.format(np.max(train_df['question_text'].apply(lambda x: len(x)))))\n",
    "print('Max character length of questions in test is {0:.0f}.'.format(np.max(test_df['question_text'].apply(lambda x: len(x)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p999 character length of questions in train is 249.\n",
      "p999 character length of questions in test is 249.\n"
     ]
    }
   ],
   "source": [
    "print('p999 character length of questions in train is {0:.0f}.'.format(np.percentile(train_df['question_text'].apply(lambda x: len(x)), 99.9)))\n",
    "print('p999 character length of questions in test is {0:.0f}.'.format(np.percentile(test_df['question_text'].apply(lambda x: len(x)), 99.9)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QIn-67cmvDFk"
   },
   "source": [
    "## **Preparing the text data**\n",
    "\n",
    "First, we will iterate over the text questions are stored, and format them into a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "bbmOu7FPvNgI",
    "outputId": "653bd496-0185-474a-d557-9d3d2dbacf08"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1044897 training questions.\n",
      "Found 261225 validation questions.\n",
      "Found 56370 test questions.\n"
     ]
    }
   ],
   "source": [
    "X_train = train_df['question_text'].fillna('+++').tolist()\n",
    "X_val = val_df['question_text'].fillna('+++').tolist()\n",
    "X_test = test_df['question_text'].fillna('+++').tolist()\n",
    "\n",
    "y_train = train_df['target']\n",
    "y_val = val_df['target']\n",
    "\n",
    "print('Found %s training questions.' % len(X_train))\n",
    "print('Found %s validation questions.' % len(X_val))\n",
    "print('Found %s test questions.' % len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "_kbWqXCezaBA",
    "outputId": "79004f92-5f67-4ceb-caf0-01a78506cb9f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (1044897, 250)\n",
      "Shape of y_train: (1044897,)\n",
      "Found 196192 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "\n",
    "MAX_SEQUENCE_LENGTH = 250\n",
    "EMBEDDING_DIM = 300\n",
    "MAX_WORDS = 100000\n",
    "\n",
    "tokenizer = Tokenizer(num_words=MAX_WORDS, lower=True, split=' ', \n",
    "                       char_level=False, oov_token=None, document_count=0,\n",
    "                      )\n",
    "                                   \n",
    "tokenizer.fit_on_texts(X_train)\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_train = pad_sequences(X_train, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "X_val = tokenizer.texts_to_sequences(X_val)\n",
    "X_val = pad_sequences(X_val, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "X_test = tokenizer.texts_to_sequences(X_test)\n",
    "X_test = pad_sequences(X_test, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "print('Shape of X_train:', X_train.shape)\n",
    "print('Shape of y_train:', y_train.shape)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "print('Found %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BUSd8dmWEUf4"
   },
   "source": [
    "# Setup Embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def loadEmbeddings(path, dimensions, mode='r', encoding=None, errors=None):\n",
    "    print('Loading embeddings from: %s' %path)\n",
    "    embeddings = {}\n",
    "    f = open(path, buffering=((2<<16) + 8), mode=mode, encoding=encoding, errors=errors)\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = ''.join(values[:-dimensions])\n",
    "        coefs = np.asarray(values[-dimensions:], dtype='float32')\n",
    "        embeddings[word] = coefs\n",
    "    f.close()\n",
    "    print('Found %s word vectors.' % len(embeddings))\n",
    "    return embeddings\n",
    "\n",
    "def loadEmbeddingsGensim(path, dimensions, binary=True):\n",
    "    print('Loading embeddings from: %s' %path)\n",
    "    embeddings = {}\n",
    "    gensim_vecs = KeyedVectors.load_word2vec_format(path, binary=binary)\n",
    "    for word, vector in zip(gensim_vecs.vocab, gensim_vecs.vectors):\n",
    "        coefs = np.asarray(vector[-dimensions:], dtype='float32')\n",
    "        embeddings[word] = coefs\n",
    "    print('Found %s word vectors.' % len(embeddings))\n",
    "    return embeddings\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0KeJJofUpQm9"
   },
   "outputs": [],
   "source": [
    "def getEmbeddingMatrix(embedding, word_index, dimensions):\n",
    "    embedding_matrix = np.zeros((len(word_index) + 1, dimensions))\n",
    "    for word, i in word_index.items():\n",
    "        embedding_vector = embedding.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            if i >= MAX_WORDS:\n",
    "                continue\n",
    "            # words not found in embedding index will be all-zeros.\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Embedding\n",
    "\n",
    "embedding_layers = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "YfAhNjEJEXmN",
    "outputId": "58618a30-4fab-44f0-8dec-591a8df2da47"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embeddings from: ../input/embeddings/glove.840B.300d/glove.840B.300d.txt\n",
      "Found 2195892 word vectors.\n"
     ]
    }
   ],
   "source": [
    "glove_path = os.path.join('..', 'input', 'embeddings', 'glove.840B.300d', 'glove.840B.300d.txt')\n",
    "embeddings_index = loadEmbeddings(glove_path, EMBEDDING_DIM)\n",
    "embedding_matrix = getEmbeddingMatrix(embeddings_index, word_index, EMBEDDING_DIM)\n",
    "del embeddings_index\n",
    "embedding_layers['glove'] = Embedding(len(word_index) + 1, EMBEDDING_DIM, weights=[embedding_matrix], input_length=MAX_SEQUENCE_LENGTH, trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "YfAhNjEJEXmN",
    "outputId": "58618a30-4fab-44f0-8dec-591a8df2da47"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embeddings from: ../input/embeddings/paragram_300_sl999/paragram_300_sl999.txt\n",
      "Found 1703663 word vectors.\n"
     ]
    }
   ],
   "source": [
    "paragram_path = os.path.join('..', 'input', 'embeddings', 'paragram_300_sl999', 'paragram_300_sl999.txt')\n",
    "embeddings_index = loadEmbeddings(paragram_path, EMBEDDING_DIM, encoding='utf8', errors='ignore')\n",
    "embedding_matrix = getEmbeddingMatrix(embeddings_index, word_index, EMBEDDING_DIM)\n",
    "del embeddings_index\n",
    "embedding_layers['paragram'] = Embedding(len(word_index) + 1, EMBEDDING_DIM, weights=[embedding_matrix], input_length=MAX_SEQUENCE_LENGTH, trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "YfAhNjEJEXmN",
    "outputId": "58618a30-4fab-44f0-8dec-591a8df2da47"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embeddings from: ../input/embeddings/wiki-news-300d-1M/wiki-news-300d-1M.vec\n",
      "Found 999995 word vectors.\n"
     ]
    }
   ],
   "source": [
    "wiki_path = os.path.join('..', 'input', 'embeddings', 'wiki-news-300d-1M', 'wiki-news-300d-1M.vec')\n",
    "embeddings_index = loadEmbeddings(wiki_path, EMBEDDING_DIM)\n",
    "embedding_matrix = getEmbeddingMatrix(embeddings_index, word_index, EMBEDDING_DIM)\n",
    "del embeddings_index\n",
    "embedding_layers['wiki'] = Embedding(len(word_index) + 1, EMBEDDING_DIM, weights=[embedding_matrix], input_length=MAX_SEQUENCE_LENGTH, trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embeddings from: ../input/embeddings/GoogleNews-vectors-negative300/GoogleNews-vectors-negative300.bin\n",
      "Found 3000000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "google_news_path = os.path.join('..', 'input', 'embeddings', 'GoogleNews-vectors-negative300', 'GoogleNews-vectors-negative300.bin')\n",
    "embeddings_index = loadEmbeddingsGensim(google_news_path, EMBEDDING_DIM)\n",
    "embedding_matrix = getEmbeddingMatrix(embeddings_index, word_index, EMBEDDING_DIM)\n",
    "del embeddings_index\n",
    "embedding_layers['google_news'] = Embedding(len(word_index) + 1, EMBEDDING_DIM, weights=[embedding_matrix], input_length=MAX_SEQUENCE_LENGTH, trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "del word_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aNd1KcNjsvxj"
   },
   "source": [
    "# Setup model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 250)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 250, 300)     58857900    input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 250, 300)     58857900    input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, 250, 300)     58857900    input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_4 (Embedding)         (None, 250, 300)     58857900    input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 250, 128)     140544      embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) (None, 250, 128)     140544      embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_3 (Bidirectional) (None, 250, 128)     140544      embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_4 (Bidirectional) (None, 250, 128)     140544      embedding_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_1 (GlobalM (None, 128)          0           bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_2 (GlobalM (None, 128)          0           bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_3 (GlobalM (None, 128)          0           bidirectional_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_4 (GlobalM (None, 128)          0           bidirectional_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 16)           2048        global_max_pooling1d_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 16)           2048        global_max_pooling1d_2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 16)           2048        global_max_pooling1d_3[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 16)           2048        global_max_pooling1d_4[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 16)           64          dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 16)           64          dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 16)           64          dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 16)           64          dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 16)           0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 16)           0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 16)           0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 16)           0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 16)           0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 16)           0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 16)           0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 16)           0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 64)           0           dropout_1[0][0]                  \n",
      "                                                                 dropout_2[0][0]                  \n",
      "                                                                 dropout_3[0][0]                  \n",
      "                                                                 dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 32)           2048        concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 32)           128         dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 32)           0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 1)            32          activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 1)            4           dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 1)            0           batch_normalization_6[0][0]      \n",
      "==================================================================================================\n",
      "Total params: 236,004,436\n",
      "Trainable params: 572,642\n",
      "Non-trainable params: 235,431,794\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dense, Dropout, Input, GlobalMaxPool1D\n",
    "from keras.layers import Conv1D, MaxPooling1D, Embedding, Bidirectional\n",
    "from keras.layers import Activation, BatchNormalization, CuDNNGRU\n",
    "from keras.layers import SpatialDropout1D, Concatenate, Flatten, Reshape\n",
    "from keras.regularizers import l2\n",
    "from keras.models import Model\n",
    "\n",
    "\n",
    "inp = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "\n",
    "a = embedding_layers['glove'] (inp)\n",
    "a = Bidirectional(CuDNNGRU(64, return_sequences=True))(a)\n",
    "a = GlobalMaxPool1D()(a)\n",
    "a = Dense(16, use_bias=False)(a)\n",
    "a = BatchNormalization()(a)\n",
    "a = Activation(\"relu\")(a)\n",
    "a = Dropout(0.1)(a)\n",
    "\n",
    "b = embedding_layers['paragram'] (inp)\n",
    "b = Bidirectional(CuDNNGRU(64, return_sequences=True))(b)\n",
    "b = GlobalMaxPool1D()(b)\n",
    "b = Dense(16, use_bias=False)(b)\n",
    "b = BatchNormalization()(b)\n",
    "b = Activation(\"relu\")(b)\n",
    "b = Dropout(0.1)(b)\n",
    "\n",
    "c = embedding_layers['wiki'] (inp)\n",
    "c = Bidirectional(CuDNNGRU(64, return_sequences=True))(c)\n",
    "c = GlobalMaxPool1D()(c)\n",
    "c = Dense(16, use_bias=False)(c)\n",
    "c = BatchNormalization()(c)\n",
    "c = Activation(\"relu\")(c)\n",
    "c = Dropout(0.1)(c)\n",
    "\n",
    "d = embedding_layers['google_news'] (inp)\n",
    "d = Bidirectional(CuDNNGRU(64, return_sequences=True))(d)\n",
    "d = GlobalMaxPool1D()(d)\n",
    "d = Dense(16, use_bias=False)(d)\n",
    "d = BatchNormalization()(d)\n",
    "d = Activation(\"relu\")(d)\n",
    "d = Dropout(0.1)(d)\n",
    "\n",
    "x = Concatenate(axis=1)([a, b, c, d])\n",
    "x = Dense(32, use_bias=False)(x)\n",
    "x = BatchNormalization()(x)\n",
    "#kernel_regularizer=l2(0.01)\n",
    "x = Activation(\"relu\")(x)\n",
    "x = Dense(1, use_bias=False)(x)\n",
    "x = BatchNormalization()(x)\n",
    "out = Activation(\"sigmoid\")(x)\n",
    "\n",
    "model = Model(inp, out)\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Lp4o2h9Fs8gP"
   },
   "source": [
    "# Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L75Rc0Gqtclm"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NVFKqCPUtJcy"
   },
   "source": [
    "# Train the model\n",
    "\n",
    "Use model checkpointing to save the model that attains the best validation loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "3OwX8ErsteZL",
    "outputId": "f718108c-5f78-4d9b-8814-c7044a9cce96"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1044897 samples, validate on 261225 samples\n",
      "Epoch 1/2\n",
      "1044897/1044897 [==============================] - 514s 491us/step - loss: 0.3674 - acc: 0.9351 - val_loss: 0.2080 - val_acc: 0.9593\n",
      "Epoch 2/2\n",
      "1044897/1044897 [==============================] - 508s 486us/step - loss: 0.1629 - acc: 0.9598 - val_loss: 0.1300 - val_acc: 0.9604\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f704a23d518>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=4, batch_size=1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NVFKqCPUtJcy"
   },
   "source": [
    "# Predict validation labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "261225/261225 [==============================] - 30s 115us/step\n"
     ]
    }
   ],
   "source": [
    "pred_val = model.predict([X_val], batch_size=1024, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NVFKqCPUtJcy"
   },
   "source": [
    "# Find best threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best threshold is 0.3600 with F1 score: 0.6699\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def bestThreshold(y_true,y_pred):\n",
    "    idx = 0\n",
    "    cur_f1 = 0\n",
    "    max_f1 = 0\n",
    "    thres = 0\n",
    "    for idx in np.arange(0.1, 0.501, 0.01):\n",
    "        cur_f1 = f1_score(y_true, np.array(y_pred)> idx)\n",
    "        if cur_f1 > max_f1:\n",
    "            max_f1 = cur_f1\n",
    "            thres = idx\n",
    "    print('best threshold is {:.4f} with F1 score: {:.4f}'.format(thres, max_f1))\n",
    "    return thres\n",
    "threshold = bestThreshold(y_val,pred_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NVFKqCPUtJcy"
   },
   "source": [
    "# Predict test labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56370/56370 [==============================] - 6s 114us/step\n"
     ]
    }
   ],
   "source": [
    "pred_test = model.predict([X_test], batch_size=1024, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NVFKqCPUtJcy"
   },
   "source": [
    "# Prepare submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df = pd.DataFrame({\"qid\":test_df[\"qid\"].values})\n",
    "submission_df['prediction'] = (pred_test > threshold).astype(int)\n",
    "submission_df.to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "capstone.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
